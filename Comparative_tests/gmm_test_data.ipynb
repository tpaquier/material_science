{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfc6031-f095-4708-b308-b796115c577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn.cluster import KMeans \n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320cc3ee-7f97-4fba-ada5-5d447e69046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cov(X,mean,weights,group):\n",
    "    \"\"\"a function to estimate the covariance with a new mean\n",
    "    Parameter\n",
    "    -------------------------------\n",
    "    X : array-like\n",
    "    the data with which we want to estimate the new covariance\n",
    "\n",
    "    mean : array-like\n",
    "    the new mean that doesn't correspond to the 'true mean'\n",
    "\n",
    "    weights : arrar-like \n",
    "    the matrix of weights of the whole data\n",
    "\n",
    "    group : int\n",
    "    the group in which we want to update\n",
    "    --------------------------------\n",
    "    \"\"\"\n",
    "    sum_of_mat = np.zeros((X.shape[1],X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        temporal_cov = weights[i,group]*np.matmul((X[i,:]-mean).reshape((X.shape[1],1)),\n",
    "                                                      (X[i,:]-mean).reshape((1,X.shape[1])))\n",
    "        sum_of_mat += temporal_cov\n",
    "    sum_of_weights = np.sum(weights[:,group])\n",
    "    weighted_sigma = sum_of_mat/sum_of_weights\n",
    "    return weighted_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e543ecb8-dab7-4d5a-85ee-4021172f8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1457065)\n",
    "n_gen = 50\n",
    "n_samples = 4*n_gen\n",
    "data_red_1 = np.random.multivariate_normal(mean=np.array([2,2]),\n",
    "                                             cov=np.array(([1,-0.25],[-0.25,1])),\n",
    "                                             size=n_gen)\n",
    "data_red_2 = np.random.uniform(low=1.0, high=3.0, size=(n_gen,2))\n",
    "\n",
    "data_blue_1 = np.random.multivariate_normal(mean=np.array([-1,-1]),\n",
    "                                            cov=np.eye(2)*0.5,\n",
    "                                            size=n_gen)\n",
    "data_blue_2 = np.random.uniform(low=-2, high=-1, size=(n_gen,2))\n",
    "\n",
    "data_red = np.vstack((data_red_1,data_red_2))\n",
    "labels_red = (np.ones(2*n_gen)*-1).reshape(2*n_gen,1)\n",
    "data_red = np.hstack((data_red,labels_red))\n",
    "\n",
    "data_blue = np.vstack((data_blue_1, data_blue_2))\n",
    "labels_blue = (np.ones(2*n_gen)).reshape(2*n_gen,1)\n",
    "data_blue = np.hstack((data_blue,labels_blue))\n",
    "\n",
    "whole_data = np.vstack((data_blue, data_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bc7b9f-5f13-4f03-bc29-27c8866bc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1457065)\n",
    "whole_data_df = pd.DataFrame(whole_data)\n",
    "whole_data_df.columns = ['x1','x2','class']\n",
    "whole_data_df['label'] = np.zeros((n_samples))\n",
    "for i in range(n_samples):\n",
    "    random = bernoulli.rvs(p=3/4)\n",
    "    if whole_data_df.loc[i,'class'] == 1 and random == 0:\n",
    "        whole_data_df.loc[i,'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791c9801-324c-45a8-a535-0089d02e54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster=3\n",
    "fit_cluster = KMeans(n_clusters=n_cluster).fit(X=whole_data_df.drop(['class','label'], axis=1).to_numpy())\n",
    "whole_data_df['cluster_lab'] = fit_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8049f2f-a2a3-42b9-a459-1087b9f937fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster = np.argmax(np.array(whole_data_df.groupby('cluster_lab')['label'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e8c390-5060-4205-b215-157411a246cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dist_centroids = np.zeros(n_cluster)\n",
    "array_centroids = fit_cluster.cluster_centers_\n",
    "for i in range(n_cluster):\n",
    "    list_dist_centroids[i] = np.linalg.norm(array_centroids[i,:] - array_centroids[positive_cluster,:])\n",
    "negative_cluster = np.argmax(list_dist_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecebe2c1-eabb-4a24-8b36-85f41a092208",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = whole_data_df[whole_data_df['cluster_lab'] == positive_cluster]\n",
    "positive_data = positive_data[positive_data['label'] == 1]\n",
    "reliable_negative = whole_data_df[whole_data_df['cluster_lab'] == negative_cluster]\n",
    "reliable_negative = reliable_negative[reliable_negative['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d86bf5-1dba-4a90-b7b4-818100b6f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = positive_data.drop(['class','label','cluster_lab'], axis=1).to_numpy()\n",
    "label_0 = reliable_negative.drop(['class','label','cluster_lab'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb4dc14-fc85-4d77-8651-ea56f90136e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(label_1,axis=0)\n",
    "mean_0 = np.mean(label_0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b1e8b3a-3e08-4fc2-9763-e5f9fc7a9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_1 = np.cov(label_1, rowvar=False)\n",
    "cov_0 = np.cov(label_0, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02e3fea-9a85-4a2d-afdc-36b587d644c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((n_samples,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b27c8a-2147-4b6c-a138-1b4d9967c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    if whole_data_df.loc[i,'cluster_lab'] == negative_cluster:\n",
    "        whole_data_df.loc[i,'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f59a25-da50-4a22-a463-e8b8624a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in range(2):\n",
    "    for i in range(n_samples):\n",
    "        if whole_data_df.loc[i,'label'] == group:\n",
    "            weights[i,group] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0ddbb0-295e-457e-a560-4ba90c6843f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0 = 1/2\n",
    "pi_1 = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38943cce-30ae-47d9-b23f-51db68ecd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pi = {'pi_0':pi_0,'pi_1':pi_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279ffba6-c517-478a-8422-781102237bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mean = {'mean_0':mean_0,'mean_1':mean_1}\n",
    "dict_cov = {'cov_0':cov_0,'cov_1':cov_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dc2a627-ca49-4ebe-b2de-f8d2b583860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gmm = whole_data_df.to_numpy()[:,:2]\n",
    "iterations = 5\n",
    "count = 0\n",
    "\n",
    "#to opti : put the weights to O/1 before so only one condition in the loop\n",
    "\n",
    "while count<=iterations:\n",
    "    count+=1\n",
    "    for group in range(2):\n",
    "        for i in range(n_samples):\n",
    "            if whole_data_df.loc[i,'label'] == 0:\n",
    "                x_test = data_gmm[i,:]\n",
    "                numerator = dict_pi['pi_{0}'.format(group)]*multivariate_normal.pdf(x=x_test,\n",
    "                                                                                    mean=dict_mean['mean_{0}'.format(group)],\n",
    "                                                                                    cov=dict_cov['cov_{0}'.format(group)],allow_singular=True)\n",
    "                denom = pi_0*multivariate_normal.pdf(x=x_test,mean=mean_0,cov=cov_0,allow_singular=True)+pi_1*multivariate_normal.pdf(x=x_test,mean=mean_1,cov=cov_1,allow_singular=True)\n",
    "                result = numerator/denom\n",
    "                if numerator<0.000001 or denom < 0.000001 or result > 1:\n",
    "                    weights[i,group] = 0\n",
    "                else:\n",
    "                    weights[i,group] = result\n",
    "        sum_of_weights = np.sum(weights[:,group])\n",
    "        dict_pi['pi_{0}'.format(group)] = np.mean(weights[:,group])\n",
    "        dict_mean['mean_{0}'.format(group)] = np.sum((data_gmm*(weights[:,group].reshape(n_samples,1))),axis=0)/sum_of_weights\n",
    "        dict_cov['cov_{0}'.format(group)] = update_cov(X=data_gmm,group=group,\n",
    "                                                       mean=dict_mean['mean_{0}'.format(group)],weights=weights)           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecd1debb-6c34-4038-a4a7-b4212f0fdd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen_test = 10\n",
    "n_samples_test = 4*n_gen_test\n",
    "data_n_test_1 = np.random.multivariate_normal(mean=np.array([2,2]),\n",
    "                                             cov=np.array(([1,-0.25],[-0.25,1])),\n",
    "                                             size=n_gen_test)\n",
    "data_n_test_2 = np.random.uniform(low=1., high=3., size=(n_gen_test,2))\n",
    "\n",
    "data_p_test_1 = np.random.multivariate_normal(mean=np.array([-1,-1]),\n",
    "                                            cov=np.eye(2)*0.5,\n",
    "                                            size=n_gen_test)\n",
    "data_p_test_2 = np.random.uniform(low=-2, high=-1., size=(n_gen_test,2))\n",
    "\n",
    "\n",
    "data_test = np.vstack((data_n_test_1,data_n_test_2,data_p_test_1,data_p_test_2))\n",
    "data_test = np.hstack((data_test,np.hstack((np.ones(n_gen_test*2)*(-1),np.ones(n_gen_test*2))).reshape(n_samples_test,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "448e2c34-4629-4e69-b151-cd807c5b957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_test = np.zeros((n_samples_test,2))\n",
    "for group in range(2):\n",
    "    for i in range(n_samples_test):\n",
    "        x_test = data_test[i,:-1]\n",
    "        numerator = dict_pi['pi_{0}'.format(group)]*multivariate_normal.pdf(x=x_test,\n",
    "                                                                            mean=dict_mean['mean_{0}'.format(group)],\n",
    "                                                                            cov=dict_cov['cov_{0}'.format(group)],allow_singular=True)\n",
    "        denom = pi_0*multivariate_normal.pdf(x=x_test,mean=mean_0,cov=cov_0,allow_singular=True)+pi_1*multivariate_normal.pdf(x=x_test,mean=mean_1,cov=cov_1,allow_singular=True)\n",
    "        result = numerator/denom\n",
    "        if numerator<0.000001 or denom < 0.000001 or result > 1:\n",
    "            weights_test[i,group] = 0\n",
    "        else:\n",
    "            weights_test[i,group] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3a528e5-0e92-4ace-b701-ee2672edae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = np.zeros((n_samples_test))\n",
    "for i in range(n_samples_test):\n",
    "    if weights_test[i,1]>=weights_test[i,0]:\n",
    "        predictions_test[i] = 1\n",
    "    else:\n",
    "        predictions_test[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7de4b4de-8767-499b-b43f-f220d2112c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_test = 0\n",
    "true_positives_test = 0\n",
    "for i in range(n_samples_test):\n",
    "    if predictions_test[i] == 1:\n",
    "        positives_test += 1\n",
    "        if data_test[i,2] == 1:\n",
    "            true_positives_test += 1\n",
    "\n",
    "precision_test = true_positives_test/positives_test\n",
    "recall_test = true_positives_test/(2*n_gen_test)\n",
    "f_1_score_test = (2*recall_test*precision_test)/(recall_test+precision_test)\n",
    "weird_metric = (recall_test**2)/(positives_test/n_samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b22cb3c9-622c-4e01-bb86-1581ba36ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.7142857142857143 \n",
      " recall : 1.0 \n",
      " f_1 score : 0.8333333333333333 \n",
      " weird metric : 1.4285714285714286\n"
     ]
    }
   ],
   "source": [
    "print('precision :', precision_test,'\\n', \n",
    "      'recall :', recall_test, '\\n', \n",
    "      'f_1 score :', f_1_score_test, '\\n', \n",
    "      'weird metric :', weird_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303a544-be87-4c33-b5a1-6d97688ad898",
   "metadata": {},
   "source": [
    "# On a less separable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea359f8d-add4-475b-b031-8e5667f328fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1457065)\n",
    "n_gen = 50\n",
    "n_samples = 4*n_gen\n",
    "data_red_1 = np.random.multivariate_normal(mean=np.array([0.5,0.5]),\n",
    "                                             cov=np.array(([2,-0.5],[-0.5,2])),\n",
    "                                             size=n_gen)\n",
    "data_red_2 = np.random.uniform(low=0.5, high=2, size=(n_gen,2))\n",
    "\n",
    "data_blue_1 = np.random.multivariate_normal(mean=np.array([-1,-1]),\n",
    "                                            cov=np.eye(2),\n",
    "                                            size=n_gen)\n",
    "data_blue_2 = np.random.uniform(low=-1, high=0., size=(n_gen,2))\n",
    "\n",
    "data_red = np.vstack((data_red_1,data_red_2))\n",
    "labels_red = (np.ones(2*n_gen)*-1).reshape(2*n_gen,1)\n",
    "data_red = np.hstack((data_red,labels_red))\n",
    "\n",
    "data_blue = np.vstack((data_blue_1, data_blue_2))\n",
    "labels_blue = (np.ones(2*n_gen)).reshape(2*n_gen,1)\n",
    "data_blue = np.hstack((data_blue,labels_blue))\n",
    "\n",
    "whole_data = np.vstack((data_blue, data_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2f5629-b583-44c3-af77-bb7ccafbf0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1457065)\n",
    "whole_data_df = pd.DataFrame(whole_data)\n",
    "whole_data_df.columns = ['x1','x2','class']\n",
    "whole_data_df['label'] = np.zeros((n_samples))\n",
    "for i in range(n_samples):\n",
    "    random = bernoulli.rvs(p=3/4)\n",
    "    if whole_data_df.loc[i,'class'] == 1 and random == 0:\n",
    "        whole_data_df.loc[i,'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b04fe13-e91a-47cc-8ccc-ec37cef7c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster=3\n",
    "fit_cluster = KMeans(n_clusters=n_cluster).fit(X=whole_data_df.drop(['class','label'], axis=1).to_numpy())\n",
    "whole_data_df['cluster_lab'] = fit_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92e5ba0-b453-48a3-b6fc-d6325f2f55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster = np.argmax(np.array(whole_data_df.groupby('cluster_lab')['label'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c58e028-7c49-4447-b905-0094d6841f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dist_centroids = np.zeros(n_cluster)\n",
    "array_centroids = fit_cluster.cluster_centers_\n",
    "for i in range(n_cluster):\n",
    "    list_dist_centroids[i] = np.linalg.norm(array_centroids[i,:] - array_centroids[positive_cluster,:])\n",
    "negative_cluster = np.argmax(list_dist_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589210ab-8c29-4a2f-b59e-275ac661b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = whole_data_df[whole_data_df['cluster_lab'] == positive_cluster]\n",
    "positive_data = positive_data[positive_data['label'] == 1]\n",
    "reliable_negative = whole_data_df[whole_data_df['cluster_lab'] == negative_cluster]\n",
    "reliable_negative = reliable_negative[reliable_negative['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7cb4ee-cc47-4a9f-83a1-f6734e513e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = positive_data.drop(['class','label','cluster_lab'], axis=1).to_numpy()\n",
    "label_0 = reliable_negative.drop(['class','label','cluster_lab'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608411a8-fa7b-48b4-af07-34b6caa966a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(label_1,axis=0)\n",
    "mean_0 = np.mean(label_0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca148fd5-96e3-4c93-ac26-62037c8886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_1 = np.cov(label_1, rowvar=False)\n",
    "cov_0 = np.cov(label_0, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd36672-36dc-4dd8-93f9-8e643160f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((n_samples,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e9045b-e514-4e15-b5c7-1325351fbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    if whole_data_df.loc[i,'cluster_lab'] == negative_cluster:\n",
    "        whole_data_df.loc[i,'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91fb66e8-ae25-4715-9449-795c092a9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in range(2):\n",
    "    for i in range(n_samples):\n",
    "        if whole_data_df.loc[i,'label'] == group:\n",
    "            weights[i,group] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23be17b9-d9f1-43e3-88a6-1dc0051a1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0 = 1/2\n",
    "pi_1 = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38902958-75ea-4d93-941b-b05f3fa77c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pi = {'pi_0':pi_0,'pi_1':pi_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fa6d17-ec7f-4ae0-b921-0519e56360d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mean = {'mean_0':mean_0,'mean_1':mean_1}\n",
    "dict_cov = {'cov_0':cov_0,'cov_1':cov_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a8d238-21e1-4847-8ecc-6a8592755d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gmm = whole_data_df.to_numpy()[:,:2]\n",
    "iterations = 5\n",
    "count = 0\n",
    "\n",
    "#to opti : put the weights to O/1 before so only one condition in the loop\n",
    "\n",
    "while count<=iterations:\n",
    "    count+=1\n",
    "    for group in range(2):\n",
    "        for i in range(n_samples):\n",
    "            if whole_data_df.loc[i,'label'] == 0:\n",
    "                x_test = data_gmm[i,:]\n",
    "                numerator = dict_pi['pi_{0}'.format(group)]*multivariate_normal.pdf(x=x_test,\n",
    "                                                                                    mean=dict_mean['mean_{0}'.format(group)],\n",
    "                                                                                    cov=dict_cov['cov_{0}'.format(group)],allow_singular=True)\n",
    "                denom = pi_0*multivariate_normal.pdf(x=x_test,mean=mean_0,cov=cov_0,allow_singular=True)+pi_1*multivariate_normal.pdf(x=x_test,mean=mean_1,cov=cov_1,allow_singular=True)\n",
    "                result = numerator/denom\n",
    "                if numerator<0.000001 or denom < 0.000001 or result > 1:\n",
    "                    weights[i,group] = 0\n",
    "                else:\n",
    "                    weights[i,group] = result\n",
    "        sum_of_weights = np.sum(weights[:,group])\n",
    "        dict_pi['pi_{0}'.format(group)] = np.mean(weights[:,group])\n",
    "        dict_mean['mean_{0}'.format(group)] = np.sum((data_gmm*(weights[:,group].reshape(n_samples,1))),axis=0)/sum_of_weights\n",
    "        dict_cov['cov_{0}'.format(group)] = update_cov(X=data_gmm,group=group,\n",
    "                                                       mean=dict_mean['mean_{0}'.format(group)],weights=weights)           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25050bd3-6280-4d54-8949-156c697f8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen_test = 10\n",
    "n_samples_test = 4*n_gen_test\n",
    "data_n_test_1 = np.random.multivariate_normal(mean=np.array([0.5,0.5]),\n",
    "                                             cov=np.array(([2,-0.5],[-0.5,5])),\n",
    "                                             size=n_gen_test)\n",
    "data_n_test_2 = np.random.uniform(low=0.5, high=2., size=(n_gen_test,2))\n",
    "\n",
    "data_p_test_1 = np.random.multivariate_normal(mean=np.array([0.5,0.5]),\n",
    "                                            cov=np.eye(2),\n",
    "                                            size=n_gen_test)\n",
    "data_p_test_2 = np.random.uniform(low=-1, high=0., size=(n_gen_test,2))\n",
    "\n",
    "\n",
    "data_test = np.vstack((data_n_test_1,data_n_test_2,data_p_test_1,data_p_test_2))\n",
    "data_test = np.hstack((data_test,np.hstack((np.ones(n_gen_test*2)*(-1),np.ones(n_gen_test*2))).reshape(n_samples_test,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce0ef40a-1404-470e-9f33-17d8e845c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_test = np.zeros((n_samples_test,2))\n",
    "for group in range(2):\n",
    "    for i in range(n_samples_test):\n",
    "        x_test = data_test[i,:-1]\n",
    "        numerator = dict_pi['pi_{0}'.format(group)]*multivariate_normal.pdf(x=x_test,\n",
    "                                                                            mean=dict_mean['mean_{0}'.format(group)],\n",
    "                                                                            cov=dict_cov['cov_{0}'.format(group)],allow_singular=True)\n",
    "        denom = pi_0*multivariate_normal.pdf(x=x_test,mean=mean_0,cov=cov_0,allow_singular=True)+pi_1*multivariate_normal.pdf(x=x_test,mean=mean_1,cov=cov_1,allow_singular=True)\n",
    "        result = numerator/denom\n",
    "        if numerator<0.000001 or denom < 0.000001 or result > 1:\n",
    "            weights_test[i,group] = 0\n",
    "        else:\n",
    "            weights_test[i,group] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ab841b-3e71-40ca-b06f-a2fc3de84a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = np.zeros((n_samples_test))\n",
    "for i in range(n_samples_test):\n",
    "    if weights_test[i,1]>=weights_test[i,0]:\n",
    "        predictions_test[i] = 1\n",
    "    else:\n",
    "        predictions_test[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2d6fbf2-cc30-411d-b599-c089fdb512dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_test = 0\n",
    "true_positives_test = 0\n",
    "for i in range(n_samples_test):\n",
    "    if predictions_test[i] == 1:\n",
    "        positives_test += 1\n",
    "        if data_test[i,2] == 1:\n",
    "            true_positives_test += 1\n",
    "\n",
    "precision_test = true_positives_test/positives_test\n",
    "recall_test = true_positives_test/(2*n_gen_test)\n",
    "f_1_score_test = (2*recall_test*precision_test)/(recall_test+precision_test)\n",
    "weird_metric = (recall_test**2)/(positives_test/n_samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f976893-d4d8-4f78-b08a-345b63849b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.5384615384615384 \n",
      " recall : 0.7 \n",
      " f_1 score : 0.608695652173913 \n",
      " weird metric : 0.7538461538461537\n"
     ]
    }
   ],
   "source": [
    "print('precision :', precision_test,'\\n', \n",
    "      'recall :', recall_test, '\\n', \n",
    "      'f_1 score :', f_1_score_test, '\\n', \n",
    "      'weird metric :', weird_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaebc6b-dbd7-41da-9707-159b9c37ae98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
