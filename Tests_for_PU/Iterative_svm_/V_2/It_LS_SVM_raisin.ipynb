{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95b5abb-b339-44c9-9e87-1342266a6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import bernoulli\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a3fd98-5d84-4fba-934b-f7beabbdc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(x,y,l_squared=1):\n",
    "    \"\"\"Gaussian kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------\n",
    "    x : float\n",
    "    a real number\n",
    "\n",
    "    y : float\n",
    "    a real number\n",
    "\n",
    "    l: float, non zero\n",
    "    a scale parameter\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    dim = x.shape[0]\n",
    "    vect = np.zeros(dim)\n",
    "    type_x = x.shape\n",
    "    type_y = y.shape\n",
    "    if len(type_x) == len(type_y):\n",
    "        d = np.exp(-((np.linalg.norm(x-y))**2)/(2*l_squared))\n",
    "        return d\n",
    "    else :\n",
    "        for i in range(dim):\n",
    "            vect[i] = np.exp(-((np.linalg.norm(x[i] - y))**2)/(2*l_squared))\n",
    "        return vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e0ef69-8689-4950-896b-97f84aa2a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2503/3020774877.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raisin_whole = raisin_whole.replace('Besni', -1)\n"
     ]
    }
   ],
   "source": [
    "raisin_whole = pd.read_csv('raisin.csv')\n",
    "raisin_whole = raisin_whole.replace('Kecimen', 1)\n",
    "raisin_whole = raisin_whole.replace('Besni', -1)\n",
    "classes_to_keep = raisin_whole['Class'].copy()\n",
    "colnames = raisin_whole.drop(['Class'], axis=1).columns\n",
    "raisin_whole = StandardScaler().fit_transform(X=raisin_whole.drop(['Class'], axis=1).to_numpy())\n",
    "raisin_whole = pd.DataFrame(raisin_whole)\n",
    "raisin_whole.columns = colnames\n",
    "raisin_whole['Class'] = classes_to_keep\n",
    "raisin, raisin_test = train_test_split(raisin_whole,train_size=0.8)\n",
    "raisin = raisin.reset_index(drop=True)\n",
    "raisin_test = raisin_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3318afa4-6772-4c61-83e8-8cd6e4d5dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = raisin.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d85402d-6f86-4497-a297-203f4acd6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raisin['label'] = np.zeros(n_samples)\n",
    "for i in range(n_samples):\n",
    "    random = bernoulli.rvs(p=3/4)\n",
    "    if raisin.loc[i,'Class'] == 1 and random == 0:\n",
    "        raisin.loc[i,'label'] = 1\n",
    "\n",
    "n_cluster = 5\n",
    "clustering = KMeans(n_clusters=n_cluster).fit(X=raisin.to_numpy()[:,:-2])\n",
    "raisin['cluster'] = clustering.labels_\n",
    "\n",
    "list_of_ratio = np.zeros(5)\n",
    "for i in range(5):\n",
    "    list_of_ratio[i] = raisin[raisin['cluster'] == i]['label'].sum()/raisin[raisin['cluster'] == i].shape[0]\n",
    "\n",
    "positive_cluster = np.argmax(list_of_ratio)\n",
    "    \n",
    "#we cannot exactly compute the ratios because the classes are so unbalanced that in any cases the number of positive\n",
    "#instances will be very small compared to the ones of unlabelled instances\n",
    "\n",
    "list_of_dist = np.zeros(5)\n",
    "for i in range(5):\n",
    "    list_of_dist[i] = np.linalg.norm(clustering.cluster_centers_[positive_cluster,:] - clustering.cluster_centers_[i,:])\n",
    "\n",
    "negative_cluster = np.argmax(list_of_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be7aa10-093e-41ca-a0fd-7d48d8f89037",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    if raisin.loc[i,'label'] == 0:\n",
    "        raisin.loc[i,'label'] = -1\n",
    "\n",
    "df_unlab_pop = raisin[raisin['label'] == -1]\n",
    "list_of_pop = pd.DataFrame(df_unlab_pop.groupby('cluster')['Class'].count())\n",
    "list_of_pop.columns = ['pop']\n",
    "list_of_pop['dist'] = list_of_dist #distance to the positive cluster\n",
    "list_of_pop = list_of_pop.sort_values('dist',ascending=False)\n",
    "list_of_pop['cumsum'] = np.cumsum(list_of_pop['pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b30cce-b331-444f-a475-60aac832ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_positives = raisin[raisin['label'] == 1]\n",
    "n_positives = reliable_positives.shape[0]\n",
    "last_step = np.where(np.array(list_of_pop['cumsum'])>n_positives)[0][0]\n",
    "index_ordered_distance = list(list_of_pop.index)\n",
    "if last_step == 0:\n",
    "    reliable_negatives = raisin[raisin['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "else:\n",
    "    compteur=0\n",
    "    reliable_negatives = raisin[raisin['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "    while compteur<last_step:\n",
    "        interm_negatives = raisin[raisin['cluster'] == index_ordered_distance[compteur+1]]\n",
    "        interm_negatives = interm_negatives[interm_negatives['label'] == -1]\n",
    "        reliable_negatives = pd.concat([reliable_negatives,interm_negatives])\n",
    "        compteur += 1\n",
    "    del interm_negatives, compteur\n",
    "\n",
    "#let's now delete the useless variables for the next steps\n",
    "del df_unlab_pop, list_of_pop, last_step, clustering, classes_to_keep\n",
    "del list_of_dist, index_ordered_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f03c4a-fe7c-4636-bc13-85ebef8f102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_negatives = reliable_negatives.sample(n=n_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d609f6a-bd69-4574-8ca6-e2703c4a4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#little precision that is quite 'funny', they use a 'random svm' for the first step of classification of the unlabelled\n",
    "#instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cb8958-a63f-4783-857e-210b54c02618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step of initialization of labels\n",
    "train_clf_data = pd.concat([reliable_positives,reliable_negatives])\n",
    "index_of_labels = list(train_clf_data.index)\n",
    "unlabelled_data = raisin.drop(labels=index_of_labels,axis=0)\n",
    "index_of_unlabelled = list(unlabelled_data.index)\n",
    "first_step_clf = SVC().fit(X=train_clf_data.drop(['Class','label','cluster'],axis=1).to_numpy(),\n",
    "                          y=train_clf_data['label'].to_numpy())\n",
    "unlabelled_data['relab'] = first_step_clf.predict(unlabelled_data.drop(['Class','label','cluster'],axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5f151-c28d-42bb-bf18-25b0a2e4d7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7c0ff1-fd73-4a40-8bae-d02da031ec63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "good_ratio = 1/2\n",
    "max_iter = 100\n",
    "compteur = 0\n",
    "train_clf_data['relab'] = train_clf_data['label'].copy()\n",
    "updated_data = pd.concat([train_clf_data,unlabelled_data])\n",
    "updated_data['is_label'] = np.zeros(n_samples)\n",
    "for i in range(n_samples):\n",
    "    if i in index_of_labels:\n",
    "        updated_data.loc[updated_data.index[i],'is_label'] = 1\n",
    "updated_data = updated_data.reset_index(drop=True)\n",
    "up_data_np = updated_data.to_numpy()[:,:-5].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while compteur<max_iter:\n",
    "    compteur += 1\n",
    "    labels = updated_data['relab'].to_numpy().reshape(1,-1)\n",
    "    first_row = np.hstack((np.array(0).reshape(1,1),(-1)*labels))\n",
    "    \n",
    "    #computation of omega and the coefficients\n",
    "    omega = np.zeros((n_samples,n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for k in range(i,n_samples):\n",
    "            omega[i,k] = rbf(x=up_data_np[i,:],y=up_data_np[k,:],l_squared=1)*labels[0,i]*labels[0,k]\n",
    "            omega[k,i] = omega[i,k]\n",
    "        omega[i,i] = 1\n",
    "\n",
    "    bot_right = omega + gamma*np.eye(n_samples)\n",
    "    bot = np.hstack((updated_data['relab'].to_numpy().reshape(n_samples,1), bot_right))\n",
    "    whole_mat = np.vstack((first_row, bot))\n",
    "    \n",
    "    del bot_right, bot, first_row\n",
    "\n",
    "    right_side = np.vstack((np.zeros(1).reshape(1,1),np.ones(n_samples).reshape(n_samples,1)))\n",
    "\n",
    "    coeffs = np.linalg.solve(a=whole_mat,b=right_side)\n",
    "\n",
    "\n",
    "    alpha = coeffs[1:]\n",
    "\n",
    "    #once we have the coefficients, we can compute the labels of the unlabelled instances\n",
    "\n",
    "    train_clf_data = pd.concat([reliable_positives,reliable_negatives])\n",
    "    index_of_labels = list(train_clf_data.index)\n",
    "    unlabelled_data = raisin.drop(labels=index_of_labels,axis=0)\n",
    "    index_of_unlabelled = list(unlabelled_data.index)\n",
    "\n",
    "    to_det_b = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        to_det_b[i] = np.sum(alpha*labels*rbf(x=up_data_np,y=up_data_np[i,:],l_squared=1))\n",
    "\n",
    "    b = np.sort(to_det_b)[int(good_ratio*n_samples)]\n",
    "    \n",
    "    check_array = np.zeros(n_samples)\n",
    "    count_diff = 0\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        if i in index_of_labels:\n",
    "            check_array[i] = 1\n",
    "        else:\n",
    "            check_array[i] = np.sign(to_det_b[i]-b)\n",
    "            if check_array[i] != updated_data.loc[i,'relab']:\n",
    "                count_diff += 1\n",
    "\n",
    "    if count_diff == 0:\n",
    "        break\n",
    "    else:\n",
    "        updated_data['relab'] = check_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5aa071c-85bf-4374-97a4-7c6136f0692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = 0\n",
    "true_positives = 0\n",
    "unlabelled_test = updated_data[updated_data['is_label'] == 0]\n",
    "for i in unlabelled_test.index:\n",
    "    if unlabelled_test.loc[i,'relab'] == 1:\n",
    "        positives += 1\n",
    "        if unlabelled_test.loc[i,'Class'] == 1:\n",
    "            true_positives += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97c32e4d-df0c-4aab-a715-c70e01abdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/positives\n",
    "recall = true_positives/updated_data[updated_data['Class'] == 1].shape[0]\n",
    "f_1 = (2*precision*recall)/(precision+recall)\n",
    "weird = (recall**2)/(positives/n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2182b19-5e8b-4783-913c-f6cde223748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.7359154929577465 \n",
      " recall :  0.5789473684210527 \n",
      " f_1 :  0.648062015503876 \n",
      " weird :  0.8497522531309742\n"
     ]
    }
   ],
   "source": [
    "print('precision : ', precision, '\\n', \n",
    "      'recall : ', recall, '\\n', \n",
    "      'f_1 : ', f_1, '\\n', \n",
    "      'weird : ', weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4215010d-7cca-4411-b0b5-ae2c32187e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test = raisin_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5618bd5-02a8-46e5-b4c1-5b17ddea9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_results = np.zeros(small_test.shape[0])\n",
    "small_test_np = small_test.to_numpy()[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c656cd-ac13-4ede-8e90-0c8015776907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:01<00:00, 154.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(small_test.shape[0])):\n",
    "    small_results[i] =np.sign(np.sum(alpha*labels*rbf(x=up_data_np,y=small_test_np[i,:],l_squared=1))-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4be81d1e-b34b-4045-88a2-c473dfce8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sm_t = 0\n",
    "tp_sm_t = 0\n",
    "for i in range(small_test.shape[0]):\n",
    "    if small_results[i] == 1:\n",
    "        pos_sm_t += 1\n",
    "        if small_test.loc[small_test.index[i],'Class'] == 1:\n",
    "            tp_sm_t += 1\n",
    "\n",
    "precision_test = tp_sm_t/pos_sm_t\n",
    "recall_test = tp_sm_t/raisin_test[raisin_test['Class'] == 1].shape[0]\n",
    "f_1_test = (2*precision_test*recall_test)/(precision_test+recall_test)\n",
    "weird_test = (recall_test**2)/(pos_sm_t/raisin_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2bc5f36-2431-48e2-a617-6694b4a18ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sm_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c0bed0a-37cb-492d-bd93-b2532944a0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_sm_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49466f30-4a83-4bf3-8d38-302ae57c0d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578947368421053"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_sm_t/pos_sm_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34e764a6-7d23-4d17-93c9-118bf0000762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test precision :  0.7578947368421053 \n",
      " test recall :  0.8089887640449438 \n",
      " f_1 test :  0.782608695652174 \n",
      " weird test :  1.240034817507093\n"
     ]
    }
   ],
   "source": [
    "print('test precision : ', precision_test, '\\n', \n",
    "      'test recall : ', recall_test, '\\n', \n",
    "      'f_1 test : ', f_1_test, '\\n', \n",
    "      'weird test : ', weird_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cab66a5-8f5f-4995-bb62-ee9b892da283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12d6ed-997b-4fcc-990a-1b4f66f50e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
