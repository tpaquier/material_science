{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95b5abb-b339-44c9-9e87-1342266a6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import bernoulli\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a3fd98-5d84-4fba-934b-f7beabbdc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(x,y,l_squared=1):\n",
    "    \"\"\"Gaussian kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------\n",
    "    x : float\n",
    "    a real number\n",
    "\n",
    "    y : float\n",
    "    a real number\n",
    "\n",
    "    l: float, non zero\n",
    "    a scale parameter\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    dim = x.shape[0]\n",
    "    vect = np.zeros(dim)\n",
    "    type_x = x.shape\n",
    "    type_y = y.shape\n",
    "    if len(type_x) == len(type_y):\n",
    "        d = np.exp(-((np.linalg.norm(x-y))**2)/(2*l_squared))\n",
    "        return d\n",
    "    else :\n",
    "        for i in range(dim):\n",
    "            vect[i] = np.exp(-((np.linalg.norm(x[i] - y))**2)/(2*l_squared))\n",
    "        return vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e0ef69-8689-4950-896b-97f84aa2a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushrooms_whole = pd.read_csv('mushroom.csv')\n",
    "classes_to_keep = mushrooms_whole['class'].copy()\n",
    "colnames = mushrooms_whole.drop(['class'], axis=1).columns\n",
    "mushrooms_whole = StandardScaler().fit_transform(X=mushrooms_whole.drop(['class'], axis=1).to_numpy())\n",
    "mushrooms_whole = pd.DataFrame(mushrooms_whole)\n",
    "mushrooms_whole.columns = colnames\n",
    "mushrooms_whole['class'] = classes_to_keep\n",
    "mushrooms, mushrooms_test = train_test_split(mushrooms_whole,train_size=9000)\n",
    "mushrooms = mushrooms.reset_index(drop=True)\n",
    "mushrooms_test = mushrooms_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3318afa4-6772-4c61-83e8-8cd6e4d5dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = mushrooms.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d85402d-6f86-4497-a297-203f4acd6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushrooms['label'] = np.zeros(n_samples)\n",
    "for i in range(n_samples):\n",
    "    random = bernoulli.rvs(p=3/4)\n",
    "    if mushrooms.loc[i,'class'] == 1 and random == 0:\n",
    "        mushrooms.loc[i,'label'] = 1\n",
    "\n",
    "n_cluster = 5\n",
    "clustering = KMeans(n_clusters=n_cluster).fit(X=mushrooms.to_numpy()[:,:-2])\n",
    "mushrooms['cluster'] = clustering.labels_\n",
    "\n",
    "list_of_ratio = np.zeros(5)\n",
    "for i in range(5):\n",
    "    list_of_ratio[i] = mushrooms[mushrooms['cluster'] == i]['label'].sum()/mushrooms[mushrooms['cluster'] == i].shape[0]\n",
    "\n",
    "positive_cluster = np.argmax(list_of_ratio)\n",
    "    \n",
    "#we cannot exactly compute the ratios because the classes are so unbalanced that in any cases the number of positive\n",
    "#instances will be very small compared to the ones of unlabelled instances\n",
    "\n",
    "list_of_dist = np.zeros(5)\n",
    "for i in range(5):\n",
    "    list_of_dist[i] = np.linalg.norm(clustering.cluster_centers_[positive_cluster,:] - clustering.cluster_centers_[i,:])\n",
    "\n",
    "negative_cluster = np.argmax(list_of_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be7aa10-093e-41ca-a0fd-7d48d8f89037",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    if mushrooms.loc[i,'label'] == 0:\n",
    "        mushrooms.loc[i,'label'] = -1\n",
    "\n",
    "df_unlab_pop = mushrooms[mushrooms['label'] == -1]\n",
    "list_of_pop = pd.DataFrame(df_unlab_pop.groupby('cluster')['class'].count())\n",
    "list_of_pop.columns = ['pop']\n",
    "list_of_pop['dist'] = list_of_dist #distance to the positive cluster\n",
    "list_of_pop = list_of_pop.sort_values('dist',ascending=False)\n",
    "list_of_pop['cumsum'] = np.cumsum(list_of_pop['pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b30cce-b331-444f-a475-60aac832ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_positives = mushrooms[mushrooms['label'] == 1]\n",
    "n_positives = reliable_positives.shape[0]\n",
    "last_step = np.where(np.array(list_of_pop['cumsum'])>n_positives)[0][0]\n",
    "index_ordered_distance = list(list_of_pop.index)\n",
    "if last_step == 0:\n",
    "    reliable_negatives = mushrooms[mushrooms['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "else:\n",
    "    compteur=0\n",
    "    reliable_negatives = mushrooms[mushrooms['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "    while compteur<last_step:\n",
    "        interm_negatives = mushrooms[mushrooms['cluster'] == index_ordered_distance[compteur+1]]\n",
    "        interm_negatives = interm_negatives[interm_negatives['label'] == -1]\n",
    "        reliable_negatives = pd.concat([reliable_negatives,interm_negatives])\n",
    "        compteur += 1\n",
    "    del interm_negatives, compteur\n",
    "\n",
    "#let's now delete the useless variables for the next steps\n",
    "del df_unlab_pop, list_of_pop, last_step, clustering, classes_to_keep\n",
    "del list_of_dist, index_ordered_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f03c4a-fe7c-4636-bc13-85ebef8f102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_negatives = reliable_negatives.head(n=n_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d609f6a-bd69-4574-8ca6-e2703c4a4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#little precision that is quite 'funny', they use a 'random svm' for the first step of classification of the unlabelled\n",
    "#instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cb8958-a63f-4783-857e-210b54c02618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step of initialization of labels\n",
    "train_clf_data = pd.concat([reliable_positives,reliable_negatives])\n",
    "index_of_labels = list(train_clf_data.index)\n",
    "unlabelled_data = mushrooms.drop(labels=index_of_labels,axis=0)\n",
    "index_of_unlabelled = list(unlabelled_data.index)\n",
    "first_step_clf = SVC().fit(X=train_clf_data.drop(['class','label','cluster'],axis=1).to_numpy(),\n",
    "                          y=train_clf_data['label'].to_numpy())\n",
    "unlabelled_data['relab'] = first_step_clf.predict(unlabelled_data.drop(['class','label','cluster'],axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1614d3d-ae34-4c77-b0d5-35b4a1d62243",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "good_ratio = 1/2\n",
    "max_iter = 1\n",
    "compteur = 0\n",
    "train_clf_data['relab'] = train_clf_data['label'].copy()\n",
    "updated_data = pd.concat([train_clf_data,unlabelled_data])\n",
    "unlabelled_data = unlabelled_data.reset_index(drop=True)\n",
    "updated_data = updated_data.reset_index(drop=True)\n",
    "updated_data['is_label'] = np.zeros(n_samples)\n",
    "for i in updated_data.index:\n",
    "    if updated_data.loc[i,'label'] == 1:\n",
    "        updated_data.loc[i,'is_label'] = 1\n",
    "up_data_np = updated_data.to_numpy()[:,:-5].copy()\n",
    "positive_index_list = list(updated_data[updated_data['label'] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7c0ff1-fd73-4a40-8bae-d02da031ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [05:03<00:00, 29.70it/s] \n",
      "100%|██████████| 9000/9000 [00:01<00:00, 5664.18it/s]\n"
     ]
    }
   ],
   "source": [
    "right_side = np.vstack((np.zeros(1).reshape(1,1),np.ones(n_samples).reshape(n_samples,1))) #its for the \n",
    "#computation of the matrix to det the coeffs so put it here to avoid doing it each time\n",
    "while compteur<max_iter:\n",
    "    compteur += 1\n",
    "    labels = updated_data['relab'].to_numpy().reshape(1,-1)\n",
    "    first_row = np.hstack((np.array(0).reshape(1,1),labels))\n",
    "    \n",
    "    #computation of omega and the coefficients\n",
    "    omega = np.zeros((n_samples,n_samples))\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        for k in range(i,n_samples):\n",
    "            omega[i,k] = rbf(x=up_data_np[i,:],y=up_data_np[k,:],l_squared=10)*labels[0,i]*labels[0,k]\n",
    "            omega[k,i] = omega[i,k]\n",
    "        omega[i,i] = 1\n",
    "\n",
    "    bot_right = omega + gamma*np.eye(n_samples)\n",
    "    bot = np.hstack((updated_data['relab'].to_numpy().reshape(n_samples,1), bot_right))\n",
    "    whole_mat = np.vstack((first_row, bot))\n",
    "    \n",
    "    del bot_right, bot, first_row\n",
    "\n",
    "    coeffs = np.linalg.solve(a=whole_mat,b=right_side)\n",
    "\n",
    "\n",
    "    alpha = coeffs[1:]\n",
    "\n",
    "    #once we have the coefficients, we can compute the labels of the unlabelled instances\n",
    "\n",
    "    updated_data['to_det_b'] = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        updated_data.loc[updated_data.index[i],'to_det_b'] = np.sum(alpha*labels*rbf(x=up_data_np,\n",
    "                                                                                     y=up_data_np[i,:],l_squared=10))\n",
    "\n",
    "    to_det_b_arr = np.array(updated_data['to_det_b']).copy()\n",
    "    b = np.sort(to_det_b_arr)[int(good_ratio*n_samples)]\n",
    "    \n",
    "    updated_data['check_array'] = np.zeros(n_samples)\n",
    "    count_diff = 0\n",
    "    \n",
    "    for i in tqdm(range(n_samples)):\n",
    "        if i in positive_index_list:\n",
    "            updated_data.loc[updated_data.index[i],'check_array'] = 1\n",
    "        else:\n",
    "            updated_data.loc[updated_data.index[i],'check_array'] = np.sign(updated_data.loc[updated_data.index[i],'to_det_b']-b)\n",
    "            if updated_data.loc[updated_data.index[i],'check_array'] != updated_data.loc[updated_data.index[i],'relab']:\n",
    "                count_diff += 1\n",
    "    \n",
    "    if count_diff == 0:\n",
    "        break\n",
    "    else:\n",
    "        updated_data['relab'] = updated_data['check_array'].copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5aa071c-85bf-4374-97a4-7c6136f0692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_for_test = updated_data[updated_data['is_label'] == 0]\n",
    "unlabelled_for_test = unlabelled_for_test.reset_index(drop=True)\n",
    "\n",
    "positives = 0\n",
    "true_positives = 0\n",
    "for i in unlabelled_for_test.index:\n",
    "    if unlabelled_for_test.loc[i,'relab'] == 1:\n",
    "        positives += 1\n",
    "        if unlabelled_for_test.loc[i,'class'] == 1:\n",
    "            true_positives += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97c32e4d-df0c-4aab-a715-c70e01abdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/positives\n",
    "recall = true_positives/unlabelled_for_test[unlabelled_for_test['class'] == 1].shape[0]\n",
    "f_1 = (2*precision*recall)/(precision+recall)\n",
    "weird = (recall**2)/(positives/unlabelled_for_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2182b19-5e8b-4783-913c-f6cde223748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.53878188443519 \n",
      " recall :  0.55406852248394 \n",
      " f_1 :  0.5463182897862232 \n",
      " weird :  0.6223737959747789\n"
     ]
    }
   ],
   "source": [
    "print('precision : ', precision, '\\n', \n",
    "      'recall : ', recall, '\\n', \n",
    "      'f_1 : ', f_1, '\\n', \n",
    "      'weird : ', weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4215010d-7cca-4411-b0b5-ae2c32187e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test = mushrooms_test.sample(frac=0.1)\n",
    "small_test = small_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5618bd5-02a8-46e5-b4c1-5b17ddea9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_results = np.zeros(small_test.shape[0])\n",
    "small_test_np = small_test.to_numpy()[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c656cd-ac13-4ede-8e90-0c8015776907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4504/4504 [38:55<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(small_test.shape[0])):\n",
    "    small_results[i] = np.sign(np.sum(alpha*labels*rbf(x=up_data_np,y=small_test_np[i,:],l_squared=10))-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4be81d1e-b34b-4045-88a2-c473dfce8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sm_t = 0\n",
    "tp_sm_t = 0\n",
    "for i in range(small_test.shape[0]):\n",
    "    if small_results[i] == 1:\n",
    "        pos_sm_t += 1\n",
    "        if small_test.loc[small_test.index[i],'class'] == 1:\n",
    "            tp_sm_t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e764a6-7d23-4d17-93c9-118bf0000762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision_sm_t = tp_sm_t/pos_sm_t\n",
    "recall_sm_t = tp_sm_t/small_test[small_test['class']==1].shape[0]\n",
    "f_1_sm_t = (2*precision_sm_t*recall_sm_t)/(precision_sm_t+recall_sm_t)\n",
    "weird_estim_sm_t = (recall_sm_t**2)/(pos_sm_t/small_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c70b4a-ab6a-447b-a23d-879d6dc7d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision on test :  0.5921787709497207 \n",
      " recall on test :  0.5583468395461912 \n",
      " f_1 on test :  0.5747653806047965 \n",
      " weird_estim on test : 0.6034066928721169\n"
     ]
    }
   ],
   "source": [
    "print('precision on test : ', precision_sm_t, '\\n', \n",
    "      'recall on test : ', recall_sm_t, '\\n', \n",
    "      'f_1 on test : ', f_1_sm_t, '\\n', \n",
    "      'weird_estim on test :', weird_estim_sm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b29eb3-b81a-45c0-bd43-2081afa1d0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
