{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595d77b3-cda0-49c6-8015-281437876e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e06ec0d-7de6-4a3f-987e-0283303cf821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10948/1604453512.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raisin_whole = raisin_whole.replace('Besni',0)\n"
     ]
    }
   ],
   "source": [
    "raisin_whole = pd.read_csv('raisin.csv')\n",
    "raisin_whole.columns = ['area', 'maj_length','min_length', 'eccentricity','convex','extent',\n",
    "                  'perimeter','class']\n",
    "classes_to_keep = raisin_whole['class'].copy()\n",
    "raisin_whole = StandardScaler().fit_transform(X=raisin_whole.to_numpy()[:,:-1])\n",
    "raisin_whole = pd.DataFrame(raisin_whole)\n",
    "raisin_whole.columns = ['area', 'maj_length','min_length', 'eccentricity','convex','extent',\n",
    "                  'perimeter']\n",
    "raisin_whole['class'] = classes_to_keep\n",
    "raisin_whole = raisin_whole.replace('Kecimen',1)\n",
    "raisin_whole = raisin_whole.replace('Besni',0)\n",
    "raisin_data = raisin_whole.sample(frac=0.8)\n",
    "list_train = raisin_data.index.copy()\n",
    "list_test = []\n",
    "for i in raisin_whole.index:\n",
    "    if i not in list_train:\n",
    "        list_test.append(i)\n",
    "raisin_test = raisin_whole.filter(items=list_test, axis=0)\n",
    "\n",
    "raisin_data = raisin_data.reset_index(drop=True)\n",
    "raisin_test = raisin_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efc8380-ab33-4d41-a563-863a920a7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cov(X,mean,weights,group):\n",
    "    \"\"\"a function to estimate the covariance with a new mean\n",
    "    Parameter\n",
    "    -------------------------------\n",
    "    X : array-like\n",
    "    the data with which we want to estimate the new covariance\n",
    "\n",
    "    mean : array-like\n",
    "    the new mean that doesn't correspond to the 'true mean'\n",
    "\n",
    "    weights : arrar-like \n",
    "    the matrix of weights of the whole data\n",
    "\n",
    "    group : int\n",
    "    the group in which we want to update\n",
    "    --------------------------------\n",
    "    \"\"\"\n",
    "    sum_of_mat = np.zeros((X.shape[1],X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        temporal_cov = weights[i,group]*np.matmul((X[i,:]-mean).reshape((X.shape[1],1)),\n",
    "                                                      (X[i,:]-mean).reshape((1,X.shape[1])))\n",
    "        sum_of_mat += temporal_cov\n",
    "    sum_of_weights = np.sum(weights[:,group])\n",
    "    weighted_sigma = sum_of_mat/sum_of_weights\n",
    "    return weighted_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774c272b-8c53-4178-a5b5-d5c5654a9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = raisin_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2710d40c-925b-45b3-82f9-7182cfb0e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raisin_data['label'] = np.ones((n_samples))*99\n",
    "\n",
    "for i in range(n_samples):\n",
    "    random = bernoulli.rvs(p=3/4)\n",
    "    if raisin_data.loc[i,'class'] == 1 and random == 0:\n",
    "        raisin_data.loc[i,'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14b5a87-e801-4e76-bfa5-f2699d598c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster=3\n",
    "fit_cluster = KMeans(n_clusters=n_cluster).fit(X=raisin_data.drop(['class','label'], axis=1).to_numpy())\n",
    "raisin_data['cluster_lab'] = fit_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773bd370-d6c4-42aa-929e-4da0bb600826",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster = np.where(np.array(raisin_data[raisin_data['label']==1].groupby('cluster_lab').count()['label']) == \n",
    "                            np.max(np.array(raisin_data[raisin_data['label']==1].groupby('cluster_lab').count()['label'])))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f59ae9-760a-40e8-8094-2d6a402aa066",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dist_centroids = np.zeros(n_cluster)\n",
    "array_centroids = fit_cluster.cluster_centers_\n",
    "for i in range(n_cluster):\n",
    "    list_dist_centroids[i] = np.linalg.norm(array_centroids[i,:] - array_centroids[positive_cluster,:])\n",
    "negative_cluster = np.argmax(list_dist_centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec72c2f9-ac6f-48bf-856f-1b8222a03a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = raisin_data[raisin_data['cluster_lab'] == positive_cluster]\n",
    "positive_data = positive_data[positive_data['label'] == 1]\n",
    "reliable_negative = raisin_data[raisin_data['cluster_lab'] == negative_cluster]\n",
    "reliable_negative = reliable_negative[reliable_negative['label'] == 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b257c93a-9a29-44f6-9bbf-81cc1d092a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = positive_data.drop(['class','label','cluster_lab'], axis=1).to_numpy()\n",
    "label_0 = reliable_negative.drop(['class','label','cluster_lab'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03358b64-d12f-4cd6-bfe7-34e4ba07cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(label_1,axis=0)\n",
    "mean_0 = np.mean(label_0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe50a9a-3198-47f8-b859-adbfefe0bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_1 = np.cov(label_1, rowvar=False)\n",
    "cov_0 = np.cov(label_0, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aa88afd-c3a1-491b-a9e1-9655c0be96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((n_samples,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c05288-aa76-447d-9e36-5ef880729697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    if raisin_data.loc[i,'cluster_lab'] == negative_cluster:\n",
    "        raisin_data.loc[i,'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a16fe270-7a04-4451-ac97-4b677e82d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in range(2):\n",
    "    for i in range(n_samples):\n",
    "        if raisin_data.loc[i,'label'] == group:\n",
    "            weights[i,group] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8279c40c-0a70-429e-bc5d-f30c9dd68ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0 = 1/2\n",
    "pi_1 = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6524239f-dd83-484a-97bf-4b7932775ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pi = {'pi_0':pi_0,'pi_1':pi_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3c629d-4168-4bfb-88d1-098a7ff4b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mean = {'mean_0':mean_0,'mean_1':mean_1}\n",
    "dict_cov = {'cov_0':cov_0,'cov_1':cov_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f296bdf-84bf-4225-bf46-b27dc5cac87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gmm = raisin_data.to_numpy()[:,:7]\n",
    "iterations = 5\n",
    "count = 0\n",
    "\n",
    "#to opti : put the weights to O/1 before so only one condition in the loop\n",
    "\n",
    "while count<=iterations:\n",
    "    count+=1\n",
    "    for group in range(2):\n",
    "        for i in range(n_samples):\n",
    "            if raisin_data.loc[i,'label'] == 99:\n",
    "                x_test = data_gmm[i,:]\n",
    "                numerator = dict_pi['pi_{0}'.format(group)]*multivariate_normal.pdf(x=x_test,\n",
    "                                                                                    mean=dict_mean['mean_{0}'.format(group)],\n",
    "                                                                                    cov=dict_cov['cov_{0}'.format(group)],allow_singular=True)\n",
    "                denom = pi_0*multivariate_normal.pdf(x=x_test,mean=mean_0,cov=cov_0,allow_singular=True)+pi_1*multivariate_normal.pdf(x=x_test,mean=mean_1,cov=cov_1,allow_singular=True)\n",
    "                result = numerator/denom\n",
    "                if numerator<0.000001 or denom < 0.000001 or result > 1:\n",
    "                    weights[i,group] = 0\n",
    "                else:\n",
    "                    weights[i,group] = result\n",
    "        sum_of_weights = np.sum(weights[:,group])\n",
    "        dict_pi['pi_{0}'.format(group)] = np.mean(weights[:,group])\n",
    "        dict_mean['mean_{0}'.format(group)] = np.sum((data_gmm*(weights[:,group].reshape(n_samples,1))),axis=0)/sum_of_weights\n",
    "        dict_cov['cov_{0}'.format(group)] = update_cov(X=data_gmm,group=group,\n",
    "                                                       mean=dict_mean['mean_{0}'.format(group)],weights=weights)           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff60e32a-b93a-491e-a865-c754323ed714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision is : 0.6096718480138169\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_samples):\n",
    "    if weights[i,1] >= weights[i,0]:\n",
    "        raisin_data.loc[i,'label'] = 1\n",
    "    else:\n",
    "        raisin_data.loc[i,'label'] = 0\n",
    "\n",
    "positives = 0\n",
    "true_positives = 0 \n",
    "for i in range(n_samples):\n",
    "    if raisin_data.loc[i,'label'] == 1:\n",
    "        positives += 1\n",
    "        if raisin_data.loc[i,'class'] == 1:\n",
    "            true_positives += 1\n",
    "\n",
    "print('the precision is :', true_positives/positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35858db5-2901-4fdb-bfaf-2c41e990ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the correct labeled points represent : 67.91666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_label = 0\n",
    "for i in range(n_samples):\n",
    "    if raisin_data.loc[i,'class'] == raisin_data.loc[i,'label']:\n",
    "        correct_label += 1\n",
    "print('the correct labeled points represent :', (correct_label*100)/n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb3773-6b55-4dcc-b6eb-61d3dab13168",
   "metadata": {},
   "source": [
    "#### The precision is still a bit approximative but I haven't tried a 'simple' SVM or GMM on the data fully labeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "730729ea-1296-4c41-840d-007997646dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_test = raisin_test.shape[0]\n",
    "weights_test = np.zeros(shape=(n_samples_test,2))\n",
    "data_gmm_test = raisin_test.to_numpy()[:,:-1]\n",
    "for group in range(2):\n",
    "    for i in range(n_samples_test):\n",
    "        x_test = data_gmm_test[i,:]\n",
    "        numerator = dict_pi['pi_{0}'.format(group)]*multivariate_normal.pdf(x=x_test,\n",
    "                                                                            mean=dict_mean['mean_{0}'.format(group)],\n",
    "                                                                            cov=dict_cov['cov_{0}'.format(group)],allow_singular=True)\n",
    "        denom = pi_0*multivariate_normal.pdf(x=x_test,mean=mean_0,cov=cov_0,allow_singular=True)+pi_1*multivariate_normal.pdf(x=x_test,mean=mean_1,cov=cov_1,allow_singular=True)\n",
    "        result = numerator/denom\n",
    "        weights_test[i,group] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e21ba61-ee78-41ec-9663-592867ae080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398373983739838\n"
     ]
    }
   ],
   "source": [
    "raisin_test['label'] = np.ones(n_samples_test)\n",
    "for i in range(n_samples_test):\n",
    "    if weights_test[i,1] > weights_test[i,0]:\n",
    "        raisin_test.loc[i,'label'] = 1\n",
    "    else:\n",
    "        raisin_test.loc[i,'label'] = 0\n",
    "\n",
    "positive_test = 0\n",
    "true_positive_test = 0\n",
    "for i in range(n_samples_test):\n",
    "    if raisin_test.loc[i,'label'] == 1:\n",
    "        positive_test += 1\n",
    "        if raisin_test.loc[i,'class'] == 1:\n",
    "            true_positive_test += 1\n",
    "\n",
    "print(true_positive_test/positive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ee330db-bf47-469b-83ba-833ccb2150f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not bad at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed28072-94c7-4144-97ab-1ad050fa406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06b6fb75-bb97-41ec-8e54-6c609fbe63ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "676e1762-8309-41f0-b7b8-878c070f9088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7902901-ad70-4614-91c8-24c1193559bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 'issue' is that it is quite 'generous' on the positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4365f0-a308-4d81-9eb2-4baa8ccfaac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
