{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b5e77a-7b5e-4aae-aa45-9070ffb8590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407766d3-269c-423a-8a09-9a55eb5d8d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3702/3608955432.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raisin_whole = raisin_whole.replace('Besni', -1)\n"
     ]
    }
   ],
   "source": [
    "raisin_whole = pd.read_csv('raisin.csv')\n",
    "raisin_whole = raisin_whole.replace('Kecimen', 1)\n",
    "raisin_whole = raisin_whole.replace('Besni', -1)\n",
    "colnames = ['area', 'maj_length','min_length', 'eccentricity','convex','extent',\n",
    "            'perimeter']\n",
    "classes_to_keep = raisin_whole['Class'].copy()\n",
    "raisin_whole = StandardScaler().fit_transform(X=raisin_whole.drop(['Class'],axis=1))\n",
    "raisin_whole = pd.DataFrame(raisin_whole)\n",
    "raisin_whole.columns = colnames\n",
    "raisin_whole['class'] = classes_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c592b362-f18e-409b-b31b-fc2a8b047c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raisin, raisin_test = train_test_split(raisin_whole,test_size=0.2)\n",
    "raisin = raisin.reset_index(drop=True)\n",
    "raisin_test = raisin_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6074ffa2-b572-4106-b2e6-f91637713e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = raisin.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ccbfc0-a951-4d1c-9f37-9a31b28653e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raisin['label'] = np.ones(n_samples)*(-1)\n",
    "for i in range(n_samples):\n",
    "    random = bernoulli.rvs(p=3/4)\n",
    "    if raisin.loc[i,'class'] == 1 and random == 0:\n",
    "        raisin.loc[i,'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f6119a-ae32-463c-b873-01826aa4a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 15\n",
    "positive_instances = raisin[raisin['label'] == 1]\n",
    "n_positives = positive_instances.shape[0]\n",
    "unlabelled_instances = raisin[raisin['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa0d874-5ac7-45ee-8fc4-a8ef372987f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 93.99it/s]\n"
     ]
    }
   ],
   "source": [
    "df_results = raisin.copy()\n",
    "df_results = raisin.drop(colnames,axis=1)\n",
    "\n",
    "for i in tqdm(range(t)):\n",
    "    u_t = unlabelled_instances.sample(n=n_positives)\n",
    "    train_set = pd.concat([positive_instances, u_t])\n",
    "    index_t = list(train_set.index)\n",
    "    f_t = SVC(decision_function_shape='ovr').fit(X=train_set.to_numpy()[:,:-2],\n",
    "                                          y=train_set['label'].to_numpy())\n",
    "    to_test = raisin.copy()\n",
    "    to_test = to_test.drop(labels=index_t,axis=0)\n",
    "    predictions_t = f_t.decision_function(X=to_test.to_numpy()[:,:-2])\n",
    "    to_test[f'score_{i}'] = predictions_t\n",
    "    to_test = to_test.drop(colnames, axis=1)\n",
    "    to_test = to_test.drop(['class','label'], axis=1)\n",
    "    df_results = df_results.merge(to_test, how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17078ecb-3c64-4473-bc32-39fd7fc577ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "raisin_bis = raisin.copy()\n",
    "df_results = df_results.drop(['class','label'], axis=1)\n",
    "df_results_gen = raisin_bis.merge(df_results, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4eb489d-f276-4a6e-a68c-4466f022ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_gen['average'] = df_results.mean(axis=1)\n",
    "df_results_gen = df_results_gen.drop(colnames,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724c48f5-699b-4bd0-b1ab-88847496149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_train = 0\n",
    "true_positives_train = 0\n",
    "\n",
    "for i in df_results_gen.index:\n",
    "    df_results_gen.loc[i,'average'] = np.sign(df_results_gen.loc[i,'average'])\n",
    "\n",
    "for i in df_results_gen.index:\n",
    "    if df_results_gen.loc[i,'average'] == 1:\n",
    "        positives_train += 1\n",
    "        if raisin.loc[i,'class'] == 1:\n",
    "            true_positives_train += 1\n",
    "\n",
    "precision = true_positives_train/positives_train\n",
    "recall = true_positives_train/(raisin[raisin['class']==1].shape[0]-n_positives)\n",
    "f_1_train = (2*precision*recall)/(precision+recall)\n",
    "weird_thing = (recall**2)/(positives_train/(n_samples-n_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e39873f-586a-44b3-8584-95204d2fb30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision on train set is :  0.825503355704698 \n",
      " recall on train set :  0.8754448398576512 \n",
      " f_1 in train set :  0.8497409326424871 \n",
      " weird on train :  1.6331084864000056\n"
     ]
    }
   ],
   "source": [
    "print('the precision on train set is : ', precision, '\\n', \n",
    "      'recall on train set : ', recall, '\\n', \n",
    "      'f_1 in train set : ', f_1_train, '\\n',\n",
    "      'weird on train : ', weird_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1fd70ef-816f-45cf-9295-1a58cd3d65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 182.82it/s]\n"
     ]
    }
   ],
   "source": [
    "df_results_test = raisin_test.copy()\n",
    "df_results_test = df_results_test.drop(colnames,axis=1)\n",
    "df_results_test = df_results_test.drop(['class'],axis=1)\n",
    "\n",
    "for i in tqdm(range(t)):\n",
    "    u_t_t = unlabelled_instances.sample(n=n_positives)\n",
    "    train_set = pd.concat([positive_instances, u_t_t])\n",
    "    f_t_t = SVC(decision_function_shape='ovr').fit(X=train_set.to_numpy()[:,:-2],\n",
    "                                          y=train_set['label'].to_numpy())\n",
    "    to_test_t = raisin_test.copy()\n",
    "    predictions_t_t = f_t_t.decision_function(X=to_test_t.to_numpy()[:,:-1])\n",
    "    df_results_test[f'score_{i}'] = predictions_t_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06923b7d-bd4e-4b65-8974-1c7aae407ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test_avg = df_results_test.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bd0ec99-514d-49db-8ad3-eaeaaeac26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_test = 0\n",
    "true_positives_test = 0\n",
    "n_samples_test = df_results_test.shape[0]\n",
    "for i in df_results_test_avg.index:\n",
    "    df_results_test_avg[i] = np.sign(df_results_test_avg[i])\n",
    "\n",
    "for i in df_results_test_avg.index:\n",
    "    if df_results_test_avg[i] == 1:\n",
    "        positives_test += 1\n",
    "        if raisin_test.loc[i, 'class'] == 1:\n",
    "            true_positives_test += 1\n",
    "\n",
    "precision_test = true_positives_test/positives_test\n",
    "recall_test = true_positives_test/(raisin_test[raisin_test['class'] == 1].shape[0])\n",
    "f_1_test = (2*precision_test*recall_test)/(precision_test+recall_test)\n",
    "weird_test = (recall_test**2)/(positives_test/n_samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46fd7b2-9374-4ed9-acf5-a4826a4c42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision on test :  0.75 \n",
      " recall on test :  0.8928571428571429 \n",
      " f_1 on test :  0.8152173913043479 \n",
      " weird estim on test :  1.4349489795918366\n"
     ]
    }
   ],
   "source": [
    "print('precision on test : ', precision_test, '\\n', \n",
    "      'recall on test : ', recall_test, '\\n',\n",
    "      'f_1 on test : ', f_1_test, '\\n',\n",
    "      'weird estim on test : ', weird_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0ecaf-2771-4127-8516-455a5b72ec69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
