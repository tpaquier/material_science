{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b567c3-6f6a-4e9d-ac8c-1101481bbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d0bb61-1b02-4ca4-8800-695c3ba6572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(x,y,l=1):\n",
    "    \"\"\"Gaussian kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------\n",
    "    x : float\n",
    "    a real number\n",
    "\n",
    "    y : float\n",
    "    a real number\n",
    "\n",
    "    l: float, non zero\n",
    "    a scale parameter\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    dim = x.shape[0]\n",
    "    vect = np.zeros(dim)\n",
    "    if dim == y.shape[0]  :\n",
    "        d = np.exp(-((np.linalg.norm(x-y))**2)/(2*(l**2)))\n",
    "        return d\n",
    "    else :\n",
    "        for i in range(dim):\n",
    "            vect[i] = np.exp(-((np.linalg.norm(x[i] - y))**2)/(2*(l**2)))\n",
    "        return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ac1307-74ff-4ce4-ab99-509a285fa289",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calculated = pd.read_csv('max_calculated.csv')\n",
    "max_elemental = pd.read_csv('max_elemental.csv')\n",
    "list_mxene = pd.read_excel('synthesized-MXenes-MAX.xlsx',sheet_name=0)\n",
    "list_failed = pd.read_excel('synthesized-MXenes-MAX.xlsx', sheet_name=2)\n",
    "n_samples = max_elemental.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278f42f6-8f6a-41ac-ac19-c654579b110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_list = pd.unique(list_mxene['MXene'])[:-1]\n",
    "to_drop = list(range(167,173))\n",
    "mx_ene_df = list_mxene.drop(labels = to_drop, axis='index')\n",
    "mx_ene_df = mx_ene_df.drop(['Unnamed: 9','Unnamed: 12','Notes','status','Reference method'],axis=1)\n",
    "max_elemental['class'] = np.zeros(max_elemental.shape[0])\n",
    "parents = mx_ene_df['Parent material'].unique()\n",
    "banned_words = ['+','Mxene','topochemical','reaction', 'or',\n",
    "               'synthesis','MXene','direct']\n",
    "complete_parents = []\n",
    "for i in range(len(parents)):\n",
    "    inter = parents[i].split()\n",
    "    for word in range(len(inter)):\n",
    "        if inter[word] not in banned_words:\n",
    "            complete_parents.append(inter[word])\n",
    "\n",
    "\n",
    "for i in range(max_elemental.shape[0]):\n",
    "    if max_elemental.loc[i,'compound_formula'] in complete_parents:\n",
    "        max_elemental.loc[i,'class'] = 1\n",
    "\n",
    "max_elemental = max_elemental.set_index('compound_formula',drop=True)\n",
    "max_elemental = max_elemental.drop(['M_element', 'A_element', 'X_element'],axis=1)\n",
    "test_tree = DecisionTreeClassifier().fit(X=max_elemental.drop(['class'],axis=1),\n",
    "                                          y=max_elemental['class'])\n",
    "\n",
    "imp_feat = test_tree.feature_importances_\n",
    "names_feat = test_tree.feature_names_in_\n",
    "df_imp_feat = pd.DataFrame(np.hstack((imp_feat.reshape(imp_feat.shape[0],1),names_feat.reshape(imp_feat.shape[0],1))))\n",
    "df_imp_feat.columns = ['features', 'name']\n",
    "df_imp_feat = df_imp_feat.sort_values('features', ascending=False)\n",
    "\n",
    "df_diff_z = df_imp_feat[df_imp_feat['features'] != 0]\n",
    "\n",
    "\n",
    "failed = list_failed['MAX']\n",
    "failed = list(failed)\n",
    "\n",
    "for i in max_elemental.index:\n",
    "    if i in failed:\n",
    "        max_elemental.loc[i,'class'] = -1\n",
    "\n",
    "\n",
    "number_of_atoms = np.zeros(n_samples)\n",
    "compteur = 0\n",
    "for element in max_elemental.index:\n",
    "    inter = []\n",
    "    for cara in element:\n",
    "        if cara in list(str(1234567890)):\n",
    "            inter.append(cara)\n",
    "    if len(inter) == 1:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + 2\n",
    "    elif len(inter) == 2:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + 1\n",
    "    elif len(inter) == 3:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + int(inter[2])\n",
    "    compteur += 1\n",
    "\n",
    "columns_name = max_elemental.columns.copy()\n",
    "normalized = max_elemental.drop(['class'],axis=1).to_numpy()/number_of_atoms.reshape(n_samples,1)\n",
    "max_elem_norm = pd.DataFrame(normalized)\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "max_elem_norm.columns = columns_name\n",
    "max_elem_norm['compound_name'] = max_elemental.index\n",
    "max_elem_norm = max_elem_norm.set_index('compound_name',drop=True)\n",
    "\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "list_of_imp_names = list(df_diff_z['name'])\n",
    "list_of_imp_names.append('label')\n",
    "list_of_imp_names.append('class')\n",
    "max_elem_norm = max_elem_norm.filter(items=list_of_imp_names, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d6cdc6-8cbc-445d-a2d1-dfcfcb20ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_elem_norm['label'] = np.zeros(n_samples)\n",
    "for i in max_elem_norm.index:\n",
    "    if max_elem_norm.loc[i,'class'] == 1:\n",
    "        max_elem_norm.loc[i,'label'] = 1\n",
    "    else:\n",
    "        max_elem_norm.loc[i,'label'] = -1\n",
    "\n",
    "positive_samples = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "unlabelled_samples = max_elem_norm[max_elem_norm['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad57c203-ea8d-4487-8e8a-0cf23ddce136",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_max_elem_norm = max_elem_norm.copy()\n",
    "list_of_positives_instances = positive_samples.index\n",
    "result_for_positive_instances = np.zeros(positive_samples.shape[0])\n",
    "general_count = 0\n",
    "for very_particular_element in list_of_positives_instances:    \n",
    "    max_elem_norm = true_max_elem_norm.drop(very_particular_element,axis=0)\n",
    "    max_elem_norm['label'] = np.zeros(n_samples -1)\n",
    "    for i in max_elem_norm.index:\n",
    "        if max_elem_norm.loc[i,'class'] == 1:\n",
    "            max_elem_norm.loc[i,'label'] = 1\n",
    "        else:\n",
    "            max_elem_norm.loc[i,'label'] = -1\n",
    "\n",
    "    positive_samples = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "    unlabelled_samples = max_elem_norm[max_elem_norm['label'] == -1]\n",
    "\n",
    "    n_cluster = 5\n",
    "    clusterized_data = KMeans(n_clusters=n_cluster).fit(max_elem_norm.to_numpy()[:,:-2])\n",
    "    max_elem_norm['cluster'] = clusterized_data.labels_\n",
    "    \n",
    "    list_of_ratio = []\n",
    "    for i in range(n_cluster):\n",
    "        list_of_ratio.append(max_elem_norm[max_elem_norm['cluster'] == i]['label'].sum()/max_elem_norm[max_elem_norm['cluster'] == i]['class'].shape[0])\n",
    "    list_of_ratio = np.array(list_of_ratio)\n",
    "    positive_cluster = np.argmax(list_of_ratio)\n",
    "    negative_cluster = np.argmin(list_of_ratio)\n",
    "    reliable_positives = max_elem_norm[max_elem_norm['cluster'] == positive_cluster]\n",
    "    reliable_positives = reliable_positives[reliable_positives['label'] == 1]\n",
    "    reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "    reliable_negatives = reliable_negatives.sample(n=reliable_positives.shape[0]) #to adjust the class balance ratio\n",
    "    #first svm part\n",
    "    gamma = 1\n",
    "    positives_array = reliable_positives.drop(['class','cluster'], axis=1)\n",
    "    negatives_array = reliable_negatives.drop(['class', 'cluster'], axis=1)\n",
    "    data_svm = np.vstack((positives_array,negatives_array))\n",
    "    n_reliable = data_svm.shape[0]\n",
    "    outcome = data_svm[:,-1]\n",
    "    data_svm = data_svm[:,:-1]\n",
    "    omega = np.zeros((n_reliable,n_reliable))\n",
    "    for k in range(n_reliable):\n",
    "        for i in range(k,n_reliable):\n",
    "            omega[k,i] = outcome[k]*outcome[i]*rbf(x=data_svm[k,:],y=data_svm[i,:],l=10)\n",
    "    omega_t = np.transpose(omega)\n",
    "    omega = omega_t + omega\n",
    "    for i in range(n_reliable):\n",
    "        omega[i,i] = 1\n",
    "\n",
    "\n",
    "    #now, computation of the rest of the matrix\n",
    "    first_row = np.hstack((0,-np.transpose(outcome)))\n",
    "    first_row = first_row.reshape(1,first_row.shape[0])\n",
    "    bot_of_mat_right = omega + (1/gamma)*np.eye(n_reliable)\n",
    "    bot_of_mat = np.hstack((outcome.reshape(n_reliable,1), bot_of_mat_right))\n",
    "    whole_mat = np.vstack((first_row, bot_of_mat))\n",
    "    right_hand = np.ones(n_reliable+1)\n",
    "    right_hand[0] = 0\n",
    "\n",
    "    #we get the coefficients\n",
    "    coeffs = np.linalg.solve(a=whole_mat,b=right_hand)\n",
    "    b = coeffs[0]\n",
    "    alpha = coeffs[1:coeffs.shape[0]]\n",
    "\n",
    "    #now we compute the wt \\phi(x) and then we order them \n",
    "    test_data = max_elem_norm.drop(['class','label','cluster'], axis=1).to_numpy()\n",
    "    results = np.zeros(n_samples -1)\n",
    "    for i in range(n_samples -1):\n",
    "        results[i] = np.sum(alpha*outcome*rbf(x=data_svm,y=test_data[i,:],l=10))\n",
    "    sorted_results = np.sort(results)\n",
    "    good_ratio = int((n_samples -1)/2)\n",
    "    b = sorted_results[good_ratio]\n",
    "\n",
    "    last_results = np.zeros(n_samples -1)\n",
    "    for i in range(n_samples -1):\n",
    "        last_results[i] = np.sign(results[i] - b)\n",
    "\n",
    "    max_elem_norm['it_results'] = last_results\n",
    "    correct_with_b = 0\n",
    "    for i in range(reliable_positives.shape[0]):\n",
    "        if max_elem_norm.loc[reliable_positives.index[i],'it_results'] == 1:\n",
    "            correct_with_b += 1\n",
    "    missclass = reliable_positives.shape[0] - correct_with_b\n",
    "    compteur = 0\n",
    "    max_iter = 500\n",
    "    while missclass!=0 and compteur<max_iter:\n",
    "        compteur += 1\n",
    "        b = (1+0.05)*b\n",
    "        last_results = np.zeros(n_samples -1)\n",
    "        for i in range(n_samples -1):\n",
    "            last_results[i] = np.sign(results[i] - b)\n",
    "\n",
    "        max_elem_norm['it_results'] = last_results\n",
    "        correct_with_b = 0\n",
    "        for i in range(reliable_positives.shape[0]):\n",
    "            if max_elem_norm.loc[reliable_positives.index[i],'it_results'] == 1:\n",
    "                correct_with_b += 1\n",
    "        missclass = reliable_positives.shape[0] - correct_with_b\n",
    "    \n",
    "    compteur=0\n",
    "    max_iter=10\n",
    "    good_ratio = int((n_samples -1)/2)\n",
    "    max_elem_norm_it = max_elem_norm\n",
    "    while True and compteur<max_iter:\n",
    "        compteur+=1\n",
    "        for i in range(n_samples -1):\n",
    "            if max_elem_norm_it.loc[max_elem_norm.index[i],'it_results'] == 0:\n",
    "                max_elem_norm_it.loc[max_elem_norm.index[i],'it_results'] = -1\n",
    "        positives_new = max_elem_norm_it[max_elem_norm_it['it_results'] == 1]\n",
    "        positives_new = positives_new[positives_new['label'] == 1]\n",
    "        negatives_new = max_elem_norm_it[max_elem_norm_it['it_results'] == -1]\n",
    "        negatives_new = negatives_new[negatives_new['label'] == -1]\n",
    "        negatives_new = negatives_new.sample(n=positives_new.shape[0])\n",
    "        #first svm part\n",
    "        gamma = 1\n",
    "        positives_array_new = positives_new.drop(['class','cluster','label'], axis=1)\n",
    "        negatives_array_new = negatives_new.drop(['class', 'cluster','label'], axis=1)\n",
    "        data_svm_it = np.vstack((positives_array_new,negatives_array_new))\n",
    "        n_reliable = data_svm_it.shape[0]\n",
    "        outcome_it = data_svm_it[:,-1].copy()\n",
    "        data_svm_it = data_svm_it[:,:-1].copy()\n",
    "        #compute omega\n",
    "        omega_it = np.zeros((n_reliable,n_reliable))\n",
    "        for k in range(n_reliable):\n",
    "            for i in range(k,n_reliable):\n",
    "                omega_it[k,i] = outcome_it[k]*outcome_it[i]*rbf(x=data_svm_it[k,:],y=data_svm_it[i,:],l=10)\n",
    "        omega_it_t = np.transpose(omega_it)\n",
    "        omega_it = omega_it+omega_it_t\n",
    "        for i in range(n_reliable):\n",
    "            omega_it[i,i] = 1\n",
    "    \n",
    "        first_row_it = np.hstack((0,-np.transpose(outcome_it)))\n",
    "        first_row_it = first_row_it.reshape(1,first_row_it.shape[0])\n",
    "        bot_of_mat_right_it = omega_it + (1/gamma)*np.eye(n_reliable)\n",
    "        bot_of_mat_it = np.hstack((outcome_it.reshape(n_reliable,1), bot_of_mat_right_it))\n",
    "        whole_mat_it = np.vstack((first_row_it, bot_of_mat_it))\n",
    "        right_hand_it = np.ones(n_reliable+1)\n",
    "        right_hand_it[0] = 0\n",
    "        coeffs_it = np.linalg.solve(a=whole_mat_it,b=right_hand_it)\n",
    "        b_it = coeffs_it[0]\n",
    "        alpha_it = coeffs_it[1:coeffs_it.shape[0]]\n",
    "        test_data_it = max_elem_norm_it.drop(['class','label','cluster','it_results'], axis=1).to_numpy()\n",
    "        results_new = np.zeros(n_samples -1)\n",
    "        #the results in the previous algo is now 'new_results'\n",
    "\n",
    "    \n",
    "        for i in range(n_samples -1):\n",
    "            results_new[i] = np.sum(alpha_it*outcome_it*rbf(x=data_svm_it,y=test_data_it[i,:],l=10))\n",
    "        sorted_results_it = np.sort(results_new)\n",
    "        b_it = sorted_results_it[good_ratio]\n",
    "        last_results_it = np.zeros(n_samples -1)\n",
    "        for i in range(n_samples -1):\n",
    "            last_results_it[i] = np.sign(results_new[i] - b)\n",
    "        correct_with_b_it = 0 \n",
    "        for i in range(max_elem_norm_it[max_elem_norm['label'] == 1].shape[0]):\n",
    "            if last_results_it[i] == 1:\n",
    "                correct_with_b_it += 1\n",
    "        missclass_it = positives_new.shape[0] - correct_with_b_it\n",
    "        compteur_bis = 0\n",
    "        max_iter_bis = 200\n",
    "        ### MODIFICATION HERE TO GET A SCORE\n",
    "        score = np.zeros(n_samples -1)\n",
    "        last_results_bis = np.zeros(n_samples -1)\n",
    "        while missclass_it!=0 and compteur_bis<max_iter_bis:\n",
    "            compteur_bis += 1\n",
    "            b_it = (1-0.05)*b_it\n",
    "            for i in range(n_samples -1):\n",
    "                last_results_bis[i] = np.sign(results_new[i] - b_it)\n",
    "                score[i] = results_new[i] - b_it\n",
    "            correct_with_b_bis = 0\n",
    "\n",
    "            for i in range(max_elem_norm_it[max_elem_norm['label'] == 1].shape[0]):\n",
    "                if last_results_bis[i] == 1:\n",
    "                    correct_with_b_bis += 1\n",
    "            missclass_it = positives_new.shape[0] - correct_with_b_bis\n",
    "        stop_counter = 0\n",
    "        for i in range(n_samples -1):\n",
    "            if max_elem_norm_it.loc[max_elem_norm.index[i],'it_results'] != last_results_bis[i]:\n",
    "                stop_counter += 1\n",
    "        if stop_counter == 0:\n",
    "            break\n",
    "            compteur = max_iter\n",
    "        else:\n",
    "            max_elem_norm_it['it_results'] = last_results_bis\n",
    "    max_elem_norm_it['score'] = score\n",
    "    alpha_it_final = alpha_it.copy()\n",
    "    outcome_it_final = outcome_it.copy()\n",
    "    result_for_positive_instances[general_count] = np.sign(np.sum(alpha_it*outcome_it*rbf(x=data_svm_it,y=true_max_elem_norm.drop(['class','label'],axis=1).loc[very_particular_element,:],l=10))-b_it)\n",
    "    general_count += 1\n",
    "\n",
    "    #reset of variables to avoid conflicts with copies\n",
    "    max_elem_norm = max_elem_norm.drop(['it_results'],axis=1)\n",
    "    del alpha, alpha_it, b, b_it, bot_of_mat, bot_of_mat_it,bot_of_mat_right\n",
    "    del bot_of_mat_right_it, coeffs, coeffs_it,correct_with_b,correct_with_b_it\n",
    "    del data_svm,data_svm_it,first_row,first_row_it,last_results,last_results_bis\n",
    "    del last_results_it, max_elem_norm_it, max_iter,max_iter_bis,missclass,missclass_it\n",
    "    del n_reliable,negatives_array,negatives_array_new,negatives_new\n",
    "    del omega,omega_it,omega_it_t,omega_t,outcome,outcome_it\n",
    "    del positives_array,positives_array_new,positives_new\n",
    "    del reliable_negatives,reliable_positives,results,results_new,right_hand,score\n",
    "    del sorted_results,sorted_results_it,stop_counter\n",
    "    del test_data,test_data_it, whole_mat,whole_mat_it,unlabelled_samples\n",
    "    del positive_cluster, negative_cluster,compteur,compteur_bis\n",
    "    del correct_with_b_bis, right_hand_it, max_elem_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af05654-6b56-434d-8958-4f8d1c8874d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR =  0.8\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0\n",
    "for i in range(result_for_positive_instances.shape[0]):\n",
    "    if result_for_positive_instances[i] == 1:\n",
    "        true_positive += 1\n",
    "\n",
    "print('TPR = ', true_positive/result_for_positive_instances.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53675f-7ece-46af-a5d8-3294d95164de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
