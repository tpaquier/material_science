{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaeae19-43f4-40d9-99c0-22c2b0a28a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install openpyxl\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d4b33d-6db6-45fe-8137-49c237395a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_path = os.getcwd()\n",
    "os.chdir('/home/onyxia/work/material_science/Spetral_clustering')\n",
    "%run rbf.ipynb\n",
    "os.chdir(actual_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ef6079-561d-4812-bf00-f871f1f5785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calculated = pd.read_csv('max_calculated.csv')\n",
    "max_elemental = pd.read_csv('max_elemental.csv')\n",
    "list_mxene = pd.read_excel('synthesized-MXenes-MAX.xlsx',sheet_name=0)\n",
    "list_failed = pd.read_excel('synthesized-MXenes-MAX.xlsx', sheet_name=2)\n",
    "n_samples = max_elemental.shape[0]\n",
    "synth_list = pd.unique(list_mxene['MXene'])[:-1]\n",
    "to_drop = list(range(167,173))\n",
    "mx_ene_df = list_mxene.drop(labels = to_drop, axis='index')\n",
    "mx_ene_df = mx_ene_df.drop(['Unnamed: 9','Unnamed: 12','Notes','status','Reference method'],axis=1)\n",
    "max_elemental['class'] = np.zeros(max_elemental.shape[0])\n",
    "parents = mx_ene_df['Parent material'].unique()\n",
    "banned_words = ['+','Mxene','topochemical','reaction', 'or',\n",
    "               'synthesis','MXene','direct']\n",
    "complete_parents = []\n",
    "for i in range(len(parents)):\n",
    "    inter = parents[i].split()\n",
    "    for word in range(len(inter)):\n",
    "        if inter[word] not in banned_words:\n",
    "            complete_parents.append(inter[word])\n",
    "\n",
    "\n",
    "for i in range(max_elemental.shape[0]):\n",
    "    if max_elemental.loc[i,'compound_formula'] in complete_parents:\n",
    "        max_elemental.loc[i,'class'] = 1\n",
    "\n",
    "max_elemental = max_elemental.set_index('compound_formula',drop=True)\n",
    "max_elemental = max_elemental.drop(['M_element', 'A_element', 'X_element'],axis=1)\n",
    "max_calculated = max_calculated.set_index('prettyformula',drop=True)\n",
    "whole_data = max_elemental.merge(max_calculated,how='inner',\n",
    "                                 left_index=True,right_index=True)\n",
    "whole_data = whole_data.drop(['PU_label','year'],axis=1)\n",
    "M_elements = pd.get_dummies(whole_data['M'],prefix='M',dtype=float)\n",
    "A_elements = pd.get_dummies(whole_data['A'],prefix='A',dtype=float)\n",
    "X_elements = pd.get_dummies(whole_data['X'],prefix='X',dtype=float)\n",
    "whole_data = whole_data.drop(['M','A','X'],axis=1)\n",
    "x_group = pd.get_dummies(whole_data['X_X_group'],prefix='x_g',dtype=float)\n",
    "a_group = pd.get_dummies(whole_data['A_A_group'],prefix='a_g',dtype=float)\n",
    "m_group = pd.get_dummies(whole_data['M_M_group'],prefix='m_g',dtype=float)\n",
    "whole_data = whole_data.drop(['X_X_group','A_A_group','M_M_group'],axis=1)\n",
    "whole_data = pd.concat([whole_data,M_elements,A_elements,X_elements,x_group,\n",
    "                       a_group,m_group],axis=1)\n",
    "\n",
    "test_tree = DecisionTreeClassifier().fit(X=whole_data.drop(['class'],axis=1),\n",
    "                                                              y=whole_data['class'])\n",
    "\n",
    "imp_feat = test_tree.feature_importances_\n",
    "names_feat = test_tree.feature_names_in_\n",
    "\n",
    "imp_feat = imp_feat.reshape(-1,1)\n",
    "names_feat = names_feat.reshape(-1,1)\n",
    "test_df = pd.DataFrame(np.hstack((names_feat,imp_feat)))\n",
    "test_df.columns = ['names_feat','imp_feat']\n",
    "test_df = test_df.set_index('names_feat',drop=True)\n",
    "test_df = test_df[test_df['imp_feat'] > 0]\n",
    "\n",
    "diff_z = list(test_df.index)\n",
    "\n",
    "\n",
    "number_of_atoms = np.zeros(n_samples)\n",
    "compteur = 0\n",
    "for element in whole_data.index:\n",
    "    inter = []\n",
    "    for cara in element:\n",
    "        if cara in list(str(1234567890)):\n",
    "            inter.append(cara)\n",
    "    if len(inter) == 1:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + 2\n",
    "    elif len(inter) == 2:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + 1\n",
    "    elif len(inter) == 3:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + int(inter[2])\n",
    "    compteur += 1\n",
    "\n",
    "columns_name = whole_data.drop(['class'],axis=1).columns.copy()\n",
    "normalized = whole_data.drop(['class'],axis=1).to_numpy()/number_of_atoms.reshape(-1,1)\n",
    "\n",
    "data_norm = pd.DataFrame(normalized)\n",
    "data_norm.columns = columns_name\n",
    "data_norm['compound_name'] = whole_data.index\n",
    "data_norm = data_norm.set_index('compound_name',drop=True)\n",
    "\n",
    "data_norm = data_norm.filter(items=list(diff_z),axis=1)\n",
    "data_norm['class'] = whole_data['class'].copy()\n",
    "\n",
    "retained_features = list(test_df.index)\n",
    "\n",
    "for feat in diff_z:\n",
    "    if len(feat) > 5:\n",
    "        retained_features.remove(feat)\n",
    "\n",
    "list_dummies = []\n",
    "\n",
    "for i in retained_features:\n",
    "    if 'M_' in i:\n",
    "        list_dummies.append(i)\n",
    "    elif 'A_' in i:\n",
    "        list_dummies.append(i)\n",
    "    elif 'X_' in i:\n",
    "        list_dummies.append(i)\n",
    "\n",
    "for col in list_dummies:\n",
    "    for row in data_norm.index:\n",
    "        if data_norm.loc[row,col] != 0:\n",
    "            data_norm.loc[row,col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3cc54c7-af7b-4d09-918c-af9b308b74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_instances = data_norm[data_norm['class'] == 1]\n",
    "index_of_positive = list(positive_instances.index)\n",
    "unlabelled_instances = data_norm.drop(labels=index_of_positive,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "175d9160-81aa-4a42-b3d8-aaa6f45f56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positives = positive_instances.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8014600-f375-4afb-91d5-aad68b1c10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9679444-e60a-481e-b222-214541fd73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = data_norm.drop(list(data_norm.columns),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd4311d-e749-4362-94b3-a7a238941bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(t):\n",
    "    u_t = unlabelled_instances.sample(n=n_positives)\n",
    "    training_set = pd.concat([positive_instances,u_t])\n",
    "    training_index = list(training_set.index)\n",
    "    clf = SVC().fit(X=training_set.drop(['class'],axis=1).to_numpy(),y=training_set['class'].to_numpy())\n",
    "    interm_df = data_norm.drop(labels=training_index,axis=0)\n",
    "    interm_df['predictions'] = clf.decision_function(X=interm_df.drop(['class'],axis=1).to_numpy())\n",
    "    df_for_merge = pd.DataFrame(interm_df['predictions'])\n",
    "    df_for_merge.columns = [f'score_{i}']\n",
    "    df_results = df_results.merge(df_for_merge, how='left', left_index=True, right_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656400ef-87a2-44dc-ae29-1406448a5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(df_results.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccce5ab9-9cdb-47dc-892f-60694a710117",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = ['score_bagging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7312a8c-d64c-4699-b22e-78bce6f0f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.sort_values(by='score_bagging', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32adce4c-fdbb-4df7-918c-cdb2037a9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.head(50)\n",
    "results_df = results_df.reset_index()\n",
    "results_df['rank_bagging'] = results_df.index\n",
    "results_df = results_df.set_index(keys='compound_name',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ec64e7e-e5cb-41c5-8b50-23ef7040e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('ordered_predictions_bagging_svm_15_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8357c52-b062-40fe-84ce-ce221f43859a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
