{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b567c3-6f6a-4e9d-ac8c-1101481bbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0bb61-1b02-4ca4-8800-695c3ba6572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(x,y,l_squared=1):\n",
    "    \"\"\"Gaussian kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------\n",
    "    x : float\n",
    "    a real number\n",
    "\n",
    "    y : float\n",
    "    a real number\n",
    "\n",
    "    l: float, non zero\n",
    "    a scale parameter\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    dim = x.shape[0]\n",
    "    vect = np.zeros(dim)\n",
    "    type_x = x.shape\n",
    "    type_y = y.shape\n",
    "    if len(type_x) == len(type_y):\n",
    "        d = np.exp(-((np.linalg.norm(x-y))**2)/(2*l_squared))\n",
    "        return d\n",
    "    else :\n",
    "        for i in range(dim):\n",
    "            vect[i] = np.exp(-((np.linalg.norm(x[i] - y))**2)/(2*l_squared))\n",
    "        return vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac1307-74ff-4ce4-ab99-509a285fa289",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calculated = pd.read_csv('max_calculated.csv')\n",
    "max_elemental = pd.read_csv('max_elemental.csv')\n",
    "list_mxene = pd.read_excel('synthesized-MXenes-MAX.xlsx',sheet_name=0)\n",
    "list_failed = pd.read_excel('synthesized-MXenes-MAX.xlsx', sheet_name=2)\n",
    "n_samples = max_elemental.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f42f6-8f6a-41ac-ac19-c654579b110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_list = pd.unique(list_mxene['MXene'])[:-1]\n",
    "to_drop = list(range(167,173))\n",
    "mx_ene_df = list_mxene.drop(labels = to_drop, axis='index')\n",
    "mx_ene_df = mx_ene_df.drop(['Unnamed: 9','Unnamed: 12','Notes','status','Reference method'],axis=1)\n",
    "max_elemental['class'] = np.zeros(max_elemental.shape[0])\n",
    "parents = mx_ene_df['Parent material'].unique()\n",
    "banned_words = ['+','Mxene','topochemical','reaction', 'or',\n",
    "               'synthesis','MXene','direct']\n",
    "complete_parents = []\n",
    "for i in range(len(parents)):\n",
    "    inter = parents[i].split()\n",
    "    for word in range(len(inter)):\n",
    "        if inter[word] not in banned_words:\n",
    "            complete_parents.append(inter[word])\n",
    "\n",
    "\n",
    "for i in range(max_elemental.shape[0]):\n",
    "    if max_elemental.loc[i,'compound_formula'] in complete_parents:\n",
    "        max_elemental.loc[i,'class'] = 1\n",
    "\n",
    "max_elemental = max_elemental.set_index('compound_formula',drop=True)\n",
    "max_elemental = max_elemental.drop(['M_element', 'A_element', 'X_element'],axis=1)\n",
    "test_tree = DecisionTreeClassifier().fit(X=max_elemental.drop(['class'],axis=1),\n",
    "                                          y=max_elemental['class'])\n",
    "\n",
    "imp_feat = test_tree.feature_importances_\n",
    "names_feat = test_tree.feature_names_in_\n",
    "df_imp_feat = pd.DataFrame(np.hstack((imp_feat.reshape(imp_feat.shape[0],1),names_feat.reshape(imp_feat.shape[0],1))))\n",
    "df_imp_feat.columns = ['features', 'name']\n",
    "df_imp_feat = df_imp_feat.sort_values('features', ascending=False)\n",
    "\n",
    "df_diff_z = df_imp_feat[df_imp_feat['features'] != 0]\n",
    "\n",
    "\n",
    "failed = list_failed['MAX']\n",
    "failed = list(failed)\n",
    "\n",
    "for i in max_elemental.index:\n",
    "    if i in failed:\n",
    "        max_elemental.loc[i,'class'] = -1\n",
    "\n",
    "\n",
    "number_of_atoms = np.zeros(n_samples)\n",
    "compteur = 0\n",
    "for element in max_elemental.index:\n",
    "    inter = []\n",
    "    for cara in element:\n",
    "        if cara in list(str(1234567890)):\n",
    "            inter.append(cara)\n",
    "    if len(inter) == 1:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + 2\n",
    "    elif len(inter) == 2:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + 1\n",
    "    elif len(inter) == 3:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + int(inter[2])\n",
    "    compteur += 1\n",
    "\n",
    "columns_name = max_elemental.columns.copy()\n",
    "normalized = max_elemental.drop(['class'],axis=1).to_numpy()/number_of_atoms.reshape(n_samples,1)\n",
    "max_elem_norm = pd.DataFrame(normalized)\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "max_elem_norm.columns = columns_name\n",
    "max_elem_norm['compound_name'] = max_elemental.index\n",
    "max_elem_norm = max_elem_norm.set_index('compound_name',drop=True)\n",
    "\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "list_of_imp_names = list(df_diff_z['name'])\n",
    "list_of_imp_names.append('label')\n",
    "list_of_imp_names.append('class')\n",
    "max_elem_norm = max_elem_norm.filter(items=list_of_imp_names, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6cdc6-8cbc-445d-a2d1-dfcfcb20ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_elem_norm['label'] = np.zeros(n_samples)\n",
    "for i in max_elem_norm.index:\n",
    "    if max_elem_norm.loc[i,'class'] == 1:\n",
    "        max_elem_norm.loc[i,'label'] = 1\n",
    "    else:\n",
    "        max_elem_norm.loc[i,'label'] = -1\n",
    "\n",
    "positive_samples = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "unlabelled_samples = max_elem_norm[max_elem_norm['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90475774-7372-4a53-9ffd-2526c75ec1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_l_squared = np.hstack((np.linspace(1,10,4,endpoint=True),\n",
    "                               np.linspace(20,100,5,endpoint=True),\n",
    "                               np.linspace(200,1000,2,endpoint=True)))\n",
    "dico_of_perf = {}\n",
    "true_max_elem_norm = max_elem_norm.copy()\n",
    "for i in tqdm(range(list_of_l_squared.shape[0])):\n",
    "    std = list_of_l_squared[i] \n",
    "    list_of_positives_instances = positive_samples.index\n",
    "    result_for_positive_instances = np.zeros(positive_samples.shape[0])\n",
    "    general_count = 0\n",
    "    for very_particular_element in list_of_positives_instances:    \n",
    "        max_elem_norm = true_max_elem_norm.drop(very_particular_element,axis=0)\n",
    "        max_elem_norm['label'] = np.zeros(n_samples -1)\n",
    "        for i in max_elem_norm.index:\n",
    "            if max_elem_norm.loc[i,'class'] == 1:\n",
    "                max_elem_norm.loc[i,'label'] = 1\n",
    "            else:\n",
    "                max_elem_norm.loc[i,'label'] = 0\n",
    "    \n",
    "        #now, the step of clusterirng and determining whether an instance is positive or not\n",
    "        n_cluster = 5\n",
    "        clustering = KMeans(n_clusters=n_cluster).fit(max_elem_norm.to_numpy()[:,:-2])\n",
    "        max_elem_norm['cluster'] = clustering.labels_\n",
    "        list_of_ratio = []\n",
    "        for i in range(n_cluster):\n",
    "            list_of_ratio.append(max_elem_norm[max_elem_norm['cluster'] == i]['label'].sum()/max_elem_norm[max_elem_norm['cluster'] == i]['class'].shape[0])\n",
    "        for i in max_elem_norm.index:\n",
    "            if max_elem_norm.loc[i,'label'] == 0:\n",
    "                max_elem_norm.loc[i,'label'] = -1\n",
    "        list_of_ratio = np.array(list_of_ratio)\n",
    "        positive_cluster = np.argmax(list_of_ratio)\n",
    "        list_of_dist = np.zeros(5)\n",
    "        for i in range(5):\n",
    "            list_of_dist[i] = np.linalg.norm(clustering.cluster_centers_[positive_cluster,:] - clustering.cluster_centers_[i,:])\n",
    "        negative_cluster = np.argmax(list_of_dist)\n",
    "        df_unlab_pop = max_elem_norm[max_elem_norm['label'] == -1]\n",
    "        list_of_pop = pd.DataFrame(df_unlab_pop.groupby('cluster')['class'].count())\n",
    "        list_of_pop.columns = ['pop']\n",
    "        list_of_pop['dist'] = list_of_dist #distance to the positive cluster\n",
    "        list_of_pop = list_of_pop.sort_values('dist',ascending=False)\n",
    "        list_of_pop['cumsum'] = np.cumsum(list_of_pop['pop'])     \n",
    "        reliable_positives = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "        n_positives = reliable_positives.shape[0]\n",
    "        last_step = np.where(np.array(list_of_pop['cumsum'])>n_positives)[0][0]\n",
    "        index_ordered_distance = list(list_of_pop.index)\n",
    "        if last_step == 0:\n",
    "            reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "            reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "            reliable_negatives = reliable_negatives.sample(n=n_positives)\n",
    "        else:\n",
    "            compteur=0\n",
    "            reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "            reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "            while compteur<last_step:\n",
    "                interm_negatives = max_elem_norm[max_elem_norm['cluster'] == index_ordered_distance[compteur+1]]\n",
    "                interm_negatives = interm_negatives[interm_negatives['label'] == -1]\n",
    "                reliable_negatives = pd.concat([reliable_negatives,interm_negatives])\n",
    "                compteur += 1\n",
    "            reliable_negatives = reliable_negatives.head(n_positives)\n",
    "        #Step of initialization of labels\n",
    "        train_clf_data = pd.concat([reliable_positives,reliable_negatives])\n",
    "        index_of_labels = list(train_clf_data.index)\n",
    "        unlabelled_data = max_elem_norm.drop(labels=index_of_labels,axis=0)\n",
    "        index_of_unlabelled = list(unlabelled_data.index)\n",
    "        first_step_clf = SVC().fit(X=train_clf_data.drop(['class','label','cluster'],axis=1).to_numpy(),\n",
    "                                  y=train_clf_data['label'].to_numpy())\n",
    "        unlabelled_data['relab'] = first_step_clf.predict(unlabelled_data.drop(['class','label','cluster'],axis=1).to_numpy())\n",
    "        gamma = 1\n",
    "        good_ratio = 1/2\n",
    "        max_iter = 1\n",
    "        compteur = 0\n",
    "        train_clf_data['relab'] = train_clf_data['label'].copy()\n",
    "        updated_data = pd.concat([train_clf_data,unlabelled_data])\n",
    "        up_data_np = updated_data.to_numpy()[:,:-4]\n",
    "        results = first_step_clf.decision_function(X=up_data_np)\n",
    "        while compteur<max_iter:\n",
    "            compteur += 1\n",
    "            labels = updated_data['relab'].to_numpy().reshape(1,-1)\n",
    "            first_row = np.hstack((np.array(0).reshape(1,1),labels))\n",
    "            \n",
    "            #computation of omega and the coefficients\n",
    "            omega = np.zeros((n_samples-1,n_samples-1))\n",
    "            for i in range(n_samples-1):\n",
    "                for k in range(i,n_samples-1):\n",
    "                    omega[i,k] = rbf(x=up_data_np[i,:],y=up_data_np[k,:],l_squared=std)*labels[0,i]*labels[0,k]\n",
    "                    omega[k,i] = omega[i,k]\n",
    "                omega[i,i] = 1\n",
    "        \n",
    "            bot_right = omega + gamma*np.eye(n_samples-1)\n",
    "            bot = np.hstack((updated_data['relab'].to_numpy().reshape(n_samples-1,1), bot_right))\n",
    "            whole_mat = np.vstack((first_row, bot))\n",
    "            \n",
    "            del bot_right, bot, first_row\n",
    "        \n",
    "            right_side = np.vstack((np.zeros(1).reshape(1,1),np.ones(n_samples-1).reshape(n_samples-1,1)))\n",
    "        \n",
    "            coeffs = np.linalg.solve(a=whole_mat,b=right_side)\n",
    "        \n",
    "        \n",
    "            alpha = coeffs[1:]\n",
    "        \n",
    "            #once we have the coefficients, we can compute the labels of the unlabelled instances\n",
    "        \n",
    "            to_det_b = np.zeros(n_samples-1)\n",
    "            for i in range(n_samples-1):\n",
    "                to_det_b[i] = np.sum(alpha*labels*rbf(x=up_data_np,y=up_data_np[i,:],l_squared=std))\n",
    "        \n",
    "            b = np.sort(to_det_b)[int(good_ratio*(n_samples-1))]\n",
    "            \n",
    "            check_array = np.zeros(n_samples-1)\n",
    "            count_diff = 0\n",
    "            \n",
    "            for i in range(n_samples-1):\n",
    "                check_array[i] = np.sign(to_det_b[i]-b)\n",
    "                if check_array[i] != updated_data.loc[updated_data.index[i],'relab']:\n",
    "                    count_diff += 1\n",
    "            if count_diff == 0:\n",
    "                break\n",
    "            else:\n",
    "                updated_data['relab'] = check_array\n",
    "    \n",
    "        last_outcome = updated_data['relab'].to_numpy()\n",
    "        result_for_positive_instances[general_count] = np.sign(np.sum(alpha*last_outcome*rbf(x=up_data_np,\n",
    "                                                                                              y=true_max_elem_norm.drop(['class','label'],\n",
    "                                                                                                                        axis=1).loc[very_particular_element,:].to_numpy(),l_squared=std))-b)\n",
    "        general_count += 1\n",
    "        updated_data = updated_data.drop(['relab'],axis=1)\n",
    "    true_positive = 0\n",
    "    for i in range(result_for_positive_instances.shape[0]):\n",
    "        if result_for_positive_instances[i] == 1:\n",
    "            true_positive += 1\n",
    "    dico_of_perf[f'{std}'] = true_positive/result_for_positive_instances.shape[0]\n",
    "        \n",
    "        #del alpha, b, check_array, clustering, coeffs, count_diff, first_step_clf, list_of_pop, list_of_ratio\n",
    "        #del last_step, list_of_dist, omega, positive_cluster, reliable_negatives, reliable_positives\n",
    "        #del whole_mat\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANT PB TO SOLVE:\n",
    "ORDER OF THE CHECK ARRAY COMPARED TO THE ONE OF THE DF, MAYBE IF \n",
    "CHECK ARRAY = DF IT CAN BE EASIER\n",
    "\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7b87c-8bf8-4493-bef5-6c2f530e26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = 0\n",
    "for i in range(result_for_positive_instances.shape[0]):\n",
    "    if result_for_positive_instances[i] == 1:\n",
    "        true_positive += 1\n",
    "\n",
    "print('TPR = ', true_positive/result_for_positive_instances.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073888c1-e31c-4dd5-9d96-d1b6b9fa51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_cluster = 5\n",
    "clustering = KMeans(n_clusters=n_cluster).fit(max_elem_norm.to_numpy()[:,:-2])\n",
    "max_elem_norm['cluster'] = clustering.labels_\n",
    "list_of_ratio = []\n",
    "for i in range(n_cluster):\n",
    "    list_of_ratio.append(max_elem_norm[max_elem_norm['cluster'] == i]['label'].sum()/max_elem_norm[max_elem_norm['cluster'] == i]['class'].shape[0])\n",
    "for i in max_elem_norm.index:\n",
    "    if max_elem_norm.loc[i,'label'] == 0:\n",
    "        max_elem_norm.loc[i,'label'] = -1\n",
    "list_of_ratio = np.array(list_of_ratio)\n",
    "positive_cluster = np.argmax(list_of_ratio)\n",
    "list_of_dist = np.zeros(5)\n",
    "for i in range(5):\n",
    "    list_of_dist[i] = np.linalg.norm(clustering.cluster_centers_[positive_cluster,:] - clustering.cluster_centers_[i,:])\n",
    "negative_cluster = np.argmax(list_of_dist)\n",
    "df_unlab_pop = max_elem_norm[max_elem_norm['label'] == -1]\n",
    "list_of_pop = pd.DataFrame(df_unlab_pop.groupby('cluster')['class'].count())\n",
    "list_of_pop.columns = ['pop']\n",
    "list_of_pop['dist'] = list_of_dist #distance to the positive cluster\n",
    "list_of_pop = list_of_pop.sort_values('dist',ascending=False)\n",
    "list_of_pop['cumsum'] = np.cumsum(list_of_pop['pop'])     \n",
    "reliable_positives = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "n_positives = reliable_positives.shape[0]\n",
    "last_step = np.where(np.array(list_of_pop['cumsum'])>n_positives)[0][0]\n",
    "index_ordered_distance = list(list_of_pop.index)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f70cf-a561-4d55-b012-6fac6091ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if last_step == 0:\n",
    "    reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "    reliable_negatives = reliable_negatives.sample(n=n_positives)\n",
    "else:\n",
    "    compteur=0\n",
    "    reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "    while compteur<last_step:\n",
    "        interm_negatives = max_elem_norm[max_elem_norm['cluster'] == index_ordered_distance[compteur+1]]\n",
    "        interm_negatives = interm_negatives[interm_negatives['label'] == -1]\n",
    "        reliable_negatives = pd.concat([reliable_negatives,interm_negatives])\n",
    "        compteur += 1\n",
    "    reliable_negatives = reliable_negatives.head(n_positives)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84f583-450a-478e-ac40-427c388401ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_elem_norm[max_elem_norm['cluster'] == positive_cluster].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af32c64-23d7-4299-ae4e-53ed2e8b0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_elem_norm[max_elem_norm['cluster'] == negative_cluster].sum()['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418584d3-51e5-4f9e-8365-61fe68ec616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dict_of_instances = {}\n",
    "for i in range(n_cluster):\n",
    "    dict_of_instances[str(i)] = max_elem_norm[max_elem_norm['cluster'] == i].sum()['class']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a656d-2fdc-493f-8792-a302089fce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_of_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01241e-30d8-421d-9d7f-00e8aec9df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = max_elem_norm[max_elem_norm['cluster'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11403b30-08c5-4ac4-9b87-128198b40b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[test['class'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ea240-773c-4fb9-8914-b4ad74050f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reliable_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173699f-50b3-43d9-a69a-4682950fceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_max_elem_norm.loc['Sc2AlC',:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064be91-17df-4222-a0da-96422d7e7cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
