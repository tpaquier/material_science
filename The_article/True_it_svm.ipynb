{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4398037-2241-41ee-a6b9-79b85bafabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cdacf4-eb14-4cdd-a1ee-637f3127c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(x,y,l_squared=1):\n",
    "    \"\"\"Gaussian kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------\n",
    "    x : float\n",
    "    a real number\n",
    "\n",
    "    y : float\n",
    "    a real number\n",
    "\n",
    "    l: float, non zero\n",
    "    a scale parameter\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    dim = x.shape[0]\n",
    "    vect = np.zeros(dim)\n",
    "    type_x = x.shape\n",
    "    type_y = y.shape\n",
    "    if len(type_x) == len(type_y):\n",
    "        d = np.exp(-((np.linalg.norm(x-y))**2)/(2*l_squared))\n",
    "        return d\n",
    "    else :\n",
    "        for i in range(dim):\n",
    "            vect[i] = np.exp(-((np.linalg.norm(x[i] - y))**2)/(2*l_squared))\n",
    "        return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7304eb9c-bdcd-4436-905b-9dff0a5d35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calculated = pd.read_csv('max_calculated.csv')\n",
    "max_elemental = pd.read_csv('max_elemental.csv')\n",
    "list_mxene = pd.read_excel('synthesized-MXenes-MAX.xlsx',sheet_name=0)\n",
    "list_failed = pd.read_excel('synthesized-MXenes-MAX.xlsx', sheet_name=2)\n",
    "n_samples = max_elemental.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725e291d-2872-4768-8a5c-3f3db2b35343",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_list = pd.unique(list_mxene['MXene'])[:-1]\n",
    "to_drop = list(range(167,173))\n",
    "mx_ene_df = list_mxene.drop(labels = to_drop, axis='index')\n",
    "mx_ene_df = mx_ene_df.drop(['Unnamed: 9','Unnamed: 12','Notes','status','Reference method'],axis=1)\n",
    "max_elemental['class'] = np.zeros(max_elemental.shape[0])\n",
    "parents = mx_ene_df['Parent material'].unique()\n",
    "banned_words = ['+','Mxene','topochemical','reaction', 'or',\n",
    "               'synthesis','MXene','direct']\n",
    "complete_parents = []\n",
    "for i in range(len(parents)):\n",
    "    inter = parents[i].split()\n",
    "    for word in range(len(inter)):\n",
    "        if inter[word] not in banned_words:\n",
    "            complete_parents.append(inter[word])\n",
    "\n",
    "\n",
    "for i in range(max_elemental.shape[0]):\n",
    "    if max_elemental.loc[i,'compound_formula'] in complete_parents:\n",
    "        max_elemental.loc[i,'class'] = 1\n",
    "\n",
    "max_elemental = max_elemental.set_index('compound_formula',drop=True)\n",
    "max_elemental = max_elemental.drop(['M_element', 'A_element', 'X_element'],axis=1)\n",
    "test_tree = DecisionTreeClassifier().fit(X=max_elemental.drop(['class'],axis=1),\n",
    "                                          y=max_elemental['class'])\n",
    "\n",
    "imp_feat = test_tree.feature_importances_\n",
    "names_feat = test_tree.feature_names_in_\n",
    "df_imp_feat = pd.DataFrame(np.hstack((imp_feat.reshape(imp_feat.shape[0],1),names_feat.reshape(imp_feat.shape[0],1))))\n",
    "df_imp_feat.columns = ['features', 'name']\n",
    "df_imp_feat = df_imp_feat.sort_values('features', ascending=False)\n",
    "\n",
    "df_diff_z = df_imp_feat[df_imp_feat['features'] != 0]\n",
    "\n",
    "\n",
    "failed = list_failed['MAX']\n",
    "failed = list(failed)\n",
    "\n",
    "for i in max_elemental.index:\n",
    "    if i in failed:\n",
    "        max_elemental.loc[i,'class'] = -1\n",
    "\n",
    "\n",
    "number_of_atoms = np.empty(n_samples)\n",
    "compteur = 0\n",
    "for element in max_elemental.index:\n",
    "    inter = []\n",
    "    for cara in element:\n",
    "        if cara in list(str(1234567890)):\n",
    "            inter.append(cara)\n",
    "    if len(inter) == 1:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + 2\n",
    "    elif len(inter) == 2:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + 1\n",
    "    elif len(inter) == 3:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + int(inter[2])\n",
    "    compteur += 1\n",
    "\n",
    "\n",
    "columns_name = max_elemental.columns.copy()\n",
    "normalized = max_elemental.drop(['class'],axis=1).to_numpy()/number_of_atoms.reshape(n_samples,1)\n",
    "max_elem_norm = pd.DataFrame(normalized)\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "max_elem_norm.columns = columns_name\n",
    "max_elem_norm['compound_name'] = max_elemental.index\n",
    "max_elem_norm = max_elem_norm.set_index('compound_name',drop=True)\n",
    "\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "list_of_imp_names = list(df_diff_z['name'])\n",
    "list_of_imp_names.append('label')\n",
    "list_of_imp_names.append('class')\n",
    "max_elem_norm = max_elem_norm.filter(items=list_of_imp_names, axis=1)\n",
    "max_elem_norm['label'] = np.zeros(n_samples)\n",
    "for i in max_elem_norm.index:\n",
    "    if max_elem_norm.loc[i,'class'] == 1:\n",
    "        max_elem_norm.loc[i,'label'] = 1\n",
    "    else:\n",
    "        max_elem_norm.loc[i,'label'] = -1\n",
    "\n",
    "positive_samples = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "unlabelled_samples = max_elem_norm[max_elem_norm['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5d6475-2cd1-42bd-92aa-ca44d900c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 8\n",
    "clustering = KMeans().fit(X=max_elem_norm.to_numpy()[:,:-2])\n",
    "max_elem_norm['cluster'] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e82570-6cba-4a4b-974a-cc630febf3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_ratio = np.zeros(n_cluster)\n",
    "for i in range(n_cluster):\n",
    "    list_of_ratio[i] = max_elem_norm[max_elem_norm['cluster'] == i]['class'].sum()/max_elem_norm[max_elem_norm['cluster'] == i].shape[0]\n",
    "#same code as before but here we use the class because it is 0 or 1\n",
    "positive_cluster = np.argmax(list_of_ratio)\n",
    "    \n",
    "#we cannot exactly compute the ratios because the classes are so unbalanced that in any cases the number of positive\n",
    "#instances will be very small compared to the ones of unlabelled instances\n",
    "\n",
    "list_of_dist = np.zeros(n_cluster)\n",
    "for i in range(n_cluster):\n",
    "    list_of_dist[i] = np.linalg.norm(clustering.cluster_centers_[positive_cluster,:] - clustering.cluster_centers_[i,:])\n",
    "\n",
    "negative_cluster = np.argmax(list_of_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be677aaa-8e73-4648-8c4f-7c0d53982885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlab_pop = max_elem_norm[max_elem_norm['label'] == -1]\n",
    "list_of_pop = pd.DataFrame(df_unlab_pop.groupby('cluster')['label'].count())\n",
    "list_of_pop.columns = ['pop']\n",
    "list_of_pop['dist'] = list_of_dist #distance to the positive cluster\n",
    "list_of_pop = list_of_pop.sort_values('dist',ascending=False)\n",
    "list_of_pop['cumsum'] = np.cumsum(list_of_pop['pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dffdd703-2c42-412e-8a70-f290e7938db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_positives = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "n_positives = reliable_positives.shape[0]\n",
    "last_step = np.where(np.array(list_of_pop['cumsum'])>n_positives)[0][0]\n",
    "index_ordered_distance = list(list_of_pop.index)\n",
    "if last_step == 0:\n",
    "    reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "else:\n",
    "    compteur=0\n",
    "    reliable_negatives = max_elem_norm[max_elem_norm['cluster'] == negative_cluster]\n",
    "    reliable_negatives = reliable_negatives[reliable_negatives['label'] == -1]\n",
    "    while compteur<last_step:\n",
    "        interm_negatives = max_elem_norm[max_elem_norm['cluster'] == index_ordered_distance[compteur+1]]\n",
    "        interm_negatives = interm_negatives[interm_negatives['label'] == -1]\n",
    "        reliable_negatives = pd.concat([reliable_negatives,interm_negatives])\n",
    "        compteur += 1\n",
    "    del interm_negatives, compteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c55e9d7-5ef8-49e8-9bba-9b87b3cbf2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_negatives = reliable_negatives.head(n=n_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb39344c-d8dd-40cf-90a8-d5008375841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step of initialization of labels\n",
    "train_clf_data = pd.concat([reliable_positives,reliable_negatives])\n",
    "index_of_labels = list(train_clf_data.index)\n",
    "unlabelled_data = max_elem_norm.drop(labels=index_of_labels,axis=0)\n",
    "index_of_unlabelled = list(unlabelled_data.index)\n",
    "first_step_clf = SVC().fit(X=train_clf_data.drop(['class','label','cluster'],axis=1).to_numpy(),\n",
    "                          y=train_clf_data['label'].to_numpy())\n",
    "unlabelled_data['relab'] = first_step_clf.predict(unlabelled_data.drop(['class','label','cluster'],axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23db0112-68c7-404d-b270-2c5477951ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "good_ratio = 1/2\n",
    "max_iter = 10\n",
    "compteur = 0\n",
    "train_clf_data['relab'] = train_clf_data['label'].copy()\n",
    "updated_data = pd.concat([train_clf_data,unlabelled_data])\n",
    "up_data_np = updated_data.to_numpy()[:,:-4].copy()\n",
    "positive_index_list = list(max_elem_norm[max_elem_norm['class'] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93695f23-4e00-4a75-99e2-38783738955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_side = np.vstack((np.zeros(1).reshape(1,1),np.ones(n_samples).reshape(n_samples,1))) #its for the \n",
    "#computation of the matrix to det the coeffs so put it here to avoid doing it each time\n",
    "while compteur<max_iter:\n",
    "    compteur += 1\n",
    "    labels = updated_data['relab'].to_numpy().reshape(1,-1)\n",
    "    first_row = np.hstack((np.array(0).reshape(1,1),labels))\n",
    "    \n",
    "    #computation of omega and the coefficients\n",
    "    omega = np.zeros((n_samples,n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for k in range(i,n_samples):\n",
    "            omega[i,k] = rbf(x=up_data_np[i,:],y=up_data_np[k,:],l_squared=10)*labels[0,i]*labels[0,k]\n",
    "            omega[k,i] = omega[i,k]\n",
    "        omega[i,i] = 1\n",
    "\n",
    "    bot_right = omega + gamma*np.eye(n_samples)\n",
    "    bot = np.hstack((updated_data['relab'].to_numpy().reshape(n_samples,1), bot_right))\n",
    "    whole_mat = np.vstack((first_row, bot))\n",
    "    \n",
    "    del bot_right, bot, first_row\n",
    "\n",
    "    coeffs = np.linalg.solve(a=whole_mat,b=right_side)\n",
    "\n",
    "\n",
    "    alpha = coeffs[1:]\n",
    "\n",
    "    #once we have the coefficients, we can compute the labels of the unlabelled instances\n",
    "\n",
    "    updated_data['to_det_b'] = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        updated_data.loc[updated_data.index[i],'to_det_b'] = np.sum(alpha*labels*rbf(x=up_data_np,y=up_data_np[i,:],l_squared=10))\n",
    "\n",
    "    to_det_b_arr = np.array(updated_data['to_det_b']).copy()\n",
    "    b = np.sort(to_det_b_arr)[int(good_ratio*n_samples)]\n",
    "    \n",
    "    updated_data['check_array'] = np.zeros(n_samples)\n",
    "    count_diff = 0\n",
    "    \n",
    "    for i in updated_data.index:\n",
    "        if i in positive_index_list:\n",
    "            updated_data.loc[i,'check_array'] = 1\n",
    "        else:\n",
    "            updated_data.loc[i,'check_array'] = np.sign(updated_data.loc[i,'to_det_b']-b)\n",
    "            if updated_data.loc[i,'check_array'] != updated_data.loc[i,'relab']:\n",
    "                count_diff += 1\n",
    "    \n",
    "    if count_diff == 0:\n",
    "        break\n",
    "    else:\n",
    "        updated_data['relab'] = updated_data['check_array'].copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3d5266d-5094-44b6-a492-2749c903c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = np.zeros(positive_samples.shape[0])\n",
    "test_set = positive_samples.to_numpy()[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3315a6e-46df-440c-8bf9-1166c274dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(positive_samples.shape[0]):\n",
    "    test_results[i] = np.sign(np.sum(alpha*labels*rbf(x=up_data_np,y=test_set[i,:],l_squared=10))-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b88b05-8aab-469f-b01b-be6769fdc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = 0\n",
    "for i in range(positive_samples.shape[0]):\n",
    "    if test_results[i] == 1:\n",
    "        true_positives += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e32f8d-2125-4f51-8c63-19cb1b5b49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = true_positives/positive_samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5349c87-da81-4ec7-acec-2183973519bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_predicted_positives = 0\n",
    "for i in updated_data.drop(labels=list(positive_samples.index),axis=0).index:\n",
    "    if updated_data.loc[i,'check_array'] == 1:\n",
    "        number_of_predicted_positives += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89137ab4-80ea-4807-98b3-288d587a8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_metric = (recall**2)/(number_of_predicted_positives/updated_data.drop(labels=list(positive_samples.index),axis=0).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aeffc10-1334-499d-932a-95c51aa2c019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2862969588550985"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c06aeda-0d99-422e-a731-c485b71e221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_pred_df = updated_data[updated_data['check_array'] == 1].sort_values(by='to_det_b',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df95e82-41ca-4e95-a352-3faf85708a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc18e693-f83b-4502-abab-b64912ffc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_pred_df = ordered_pred_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58db59ab-600c-4f21-9194-c5317b6e2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_pred_df = pd.DataFrame(ordered_pred_df['to_det_b'])\n",
    "ordered_pred_df.columns = ['score_it_svm']\n",
    "ordered_pred_df = ordered_pred_df.reset_index()\n",
    "ordered_pred_df['rank_it_svm'] = ordered_pred_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99751082-de9d-46d4-9181-b44f5d050d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_pred_df = ordered_pred_df.set_index('compound_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4cf6f37-b4aa-4a48-b9bc-c9bdd91ac583",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_pred_df.to_csv(path_or_buf = 'ordered_predictions_it_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a4136e1-b2bd-4708-8d5b-608838e838d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_likely = list(ordered_pred_df.index)\n",
    "same = 0\n",
    "for i in predicted_likely:\n",
    "    if i in list(positive_samples.index):\n",
    "        same += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "142658e9-2fac-4ff5-8610-32913dbc15b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2197d-1ac0-47c7-8605-f0d13f1ba787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
