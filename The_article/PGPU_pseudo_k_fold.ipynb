{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c5e184-b290-426f-9288-cdd8ea097bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "!pip install openpyxl\n",
    "!pip install qpsolvers\n",
    "import qpsolvers\n",
    "!pip install qpsolvers[cvxopt]\n",
    "!pip install qpsolvers[open_source_solvers]\n",
    "!pip install qpsolvers[clarabel]\n",
    "from qpsolvers import solve_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c703bf1-c54e-4700-a0fd-cce45b5d6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(x,y,l=1):\n",
    "    \"\"\"Gaussian kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------\n",
    "    x : float\n",
    "    a real number\n",
    "\n",
    "    y : float\n",
    "    a real number\n",
    "\n",
    "    l: float, non zero\n",
    "    a scale parameter\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    dim = x.shape[0]\n",
    "    vect = np.empty(dim)\n",
    "    if dim == y.shape[0]  :\n",
    "        d = np.exp((-1)*((np.linalg.norm(x-y))/(2*(l**2))))\n",
    "        return d\n",
    "    else :\n",
    "        for i in range(dim):\n",
    "            vect[i] = np.exp((-1)*(np.linalg.norm(x[i] - y))/(2*(l**2)))\n",
    "        return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43df753-e8d8-4d18-81d1-d922cbf9eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calculated = pd.read_csv('max_calculated.csv')\n",
    "max_elemental = pd.read_csv('max_elemental.csv')\n",
    "list_mxene = pd.read_excel('synthesized-MXenes-MAX.xlsx',sheet_name=0)\n",
    "list_failed = pd.read_excel('synthesized-MXenes-MAX.xlsx', sheet_name=2)\n",
    "n_samples = max_elemental.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5023fe-45f6-43a6-89de-d3bd9c3ddfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_list = pd.unique(list_mxene['MXene'])[:-1]\n",
    "to_drop = list(range(167,173))\n",
    "mx_ene_df = list_mxene.drop(labels = to_drop, axis='index')\n",
    "mx_ene_df = mx_ene_df.drop(['Unnamed: 9','Unnamed: 12','Notes','status','Reference method'],axis=1)\n",
    "max_elemental['class'] = np.zeros(max_elemental.shape[0])\n",
    "parents = mx_ene_df['Parent material'].unique()\n",
    "banned_words = ['+','Mxene','topochemical','reaction', 'or',\n",
    "               'synthesis','MXene','direct']\n",
    "complete_parents = []\n",
    "for i in range(len(parents)):\n",
    "    inter = parents[i].split()\n",
    "    for word in range(len(inter)):\n",
    "        if inter[word] not in banned_words:\n",
    "            complete_parents.append(inter[word])\n",
    "\n",
    "\n",
    "for i in range(max_elemental.shape[0]):\n",
    "    if max_elemental.loc[i,'compound_formula'] in complete_parents:\n",
    "        max_elemental.loc[i,'class'] = 1\n",
    "\n",
    "max_elemental = max_elemental.set_index('compound_formula',drop=True)\n",
    "max_elemental = max_elemental.drop(['M_element', 'A_element', 'X_element'],axis=1)\n",
    "test_tree = DecisionTreeClassifier().fit(X=max_elemental.drop(['class'],axis=1),\n",
    "                                          y=max_elemental['class'])\n",
    "\n",
    "imp_feat = test_tree.feature_importances_\n",
    "names_feat = test_tree.feature_names_in_\n",
    "df_imp_feat = pd.DataFrame(np.hstack((imp_feat.reshape(imp_feat.shape[0],1),names_feat.reshape(imp_feat.shape[0],1))))\n",
    "df_imp_feat.columns = ['features', 'name']\n",
    "df_imp_feat = df_imp_feat.sort_values('features', ascending=False)\n",
    "\n",
    "df_diff_z = df_imp_feat[df_imp_feat['features'] != 0]\n",
    "\n",
    "\n",
    "failed = list_failed['MAX']\n",
    "failed = list(failed)\n",
    "\n",
    "for i in max_elemental.index:\n",
    "    if i in failed:\n",
    "        max_elemental.loc[i,'class'] = -1\n",
    "\n",
    "\n",
    "number_of_atoms = np.empty(n_samples)\n",
    "compteur = 0\n",
    "for element in max_elemental.index:\n",
    "    inter = []\n",
    "    for cara in element:\n",
    "        if cara in list(str(1234567890)):\n",
    "            inter.append(cara)\n",
    "    if len(inter) == 1:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + 2\n",
    "    elif len(inter) == 2:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + 1\n",
    "    elif len(inter) == 3:\n",
    "        number_of_atoms[compteur] = int(inter[0]) + int(inter[1]) + int(inter[2])\n",
    "    compteur += 1\n",
    "\n",
    "\n",
    "columns_name = max_elemental.columns.copy()\n",
    "normalized = max_elemental.drop(['class'],axis=1).to_numpy()/number_of_atoms.reshape(n_samples,1)\n",
    "max_elem_norm = pd.DataFrame(normalized)\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "max_elem_norm.columns = columns_name\n",
    "max_elem_norm['compound_name'] = max_elemental.index\n",
    "max_elem_norm = max_elem_norm.set_index('compound_name',drop=True)\n",
    "\n",
    "max_elem_norm['class'] = max_elemental['class'].copy()\n",
    "list_of_imp_names = list(df_diff_z['name'])\n",
    "list_of_imp_names.append('label')\n",
    "list_of_imp_names.append('class')\n",
    "max_elem_norm = max_elem_norm.filter(items=list_of_imp_names, axis=1)\n",
    "max_elem_norm['label'] = np.zeros(n_samples)\n",
    "for i in max_elem_norm.index:\n",
    "    if max_elem_norm.loc[i,'class'] == 1:\n",
    "        max_elem_norm.loc[i,'label'] = 1\n",
    "    else:\n",
    "        max_elem_norm.loc[i,'label'] = -1\n",
    "\n",
    "positive_samples = max_elem_norm[max_elem_norm['label'] == 1]\n",
    "unlabelled_samples = max_elem_norm[max_elem_norm['label'] == -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeab9c1d-2f82-4351-a370-49fbf391b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the element taken out of the sample is :  Ti2AlC \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.436030276308054\n",
      "the element taken out of the sample is :  Ti2SC \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.4554967972590496\n",
      "the element taken out of the sample is :  Ti2ZnC \n",
      " the recall of pgpu on train set is : 0.8571428571428571 \n",
      " the weird metric of pgpu on train set is : 2.0037911425124935\n",
      "the element taken out of the sample is :  V2AlC \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.5024988466861446\n",
      "the element taken out of the sample is :  Nb2AlC \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.5008832565284176\n",
      "the element taken out of the sample is :  Ta2AlC \n",
      " the recall of pgpu on train set is : 1.0 \n",
      " the weird metric of pgpu on train set is : 1.489459815546772\n",
      "the element taken out of the sample is :  Ti3AlC2 \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.4833383938059814\n",
      "the element taken out of the sample is :  Ti3SiC2 \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.4272202746129126\n",
      "the element taken out of the sample is :  Ti3ZnC2 \n",
      " the recall of pgpu on train set is : 0.8571428571428571 \n",
      " the weird metric of pgpu on train set is : 1.9965659340659339\n",
      "the element taken out of the sample is :  Ti3SnC2 \n",
      " the recall of pgpu on train set is : 0.8571428571428571 \n",
      " the weird metric of pgpu on train set is : 1.9893926432848585\n",
      "the element taken out of the sample is :  V4AlC3 \n",
      " the recall of pgpu on train set is : 1.0 \n",
      " the weird metric of pgpu on train set is : 1.0\n",
      "the element taken out of the sample is :  Nb4AlC3 \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.4419642857142856\n",
      "the element taken out of the sample is :  Ta4AlC3 \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.4539806547619045\n",
      "the element taken out of the sample is :  Ti2AlN \n",
      " the recall of pgpu on train set is : 0.7857142857142857 \n",
      " the weird metric of pgpu on train set is : 1.4434554587088195\n",
      "the element taken out of the sample is :  Ti4AlN3 \n",
      " the recall of pgpu on train set is : 1.0 \n",
      " the weird metric of pgpu on train set is : 1.0\n"
     ]
    }
   ],
   "source": [
    "true_max_elem = max_elem_norm.copy()\n",
    "list_of_positive_names = positive_samples.index\n",
    "result_for_positive_instances = np.zeros(positive_samples.shape[0])\n",
    "gen_count = 0\n",
    "\n",
    "for particular_element in list_of_positive_names:\n",
    "    element_to_test = true_max_elem.drop(['class','label'],axis=1).loc[particular_element,:].to_numpy()\n",
    "    max_elem_norm = true_max_elem.drop(particular_element,axis=0)\n",
    "\n",
    "    \n",
    "    svm_train = SVC(kernel='sigmoid', probability = True).fit(X=max_elem_norm.to_numpy()[:,:-2],\n",
    "                                                          y=max_elem_norm.to_numpy()[:,-1])\n",
    "    probas = svm_train.predict_proba(max_elem_norm.to_numpy()[:,:-2])\n",
    "    proba_gap = np.zeros(n_samples -1)\n",
    "    for i in range(n_samples -1):\n",
    "        proba_gap[i] = probas[i,1] - probas[i,0]\n",
    "\n",
    "\n",
    "    max_elem_norm['proba_gap'] = proba_gap\n",
    "\n",
    "    n_min = 4 #we increase it a bit as the classes are really unbalanced\n",
    "\n",
    "    l_boundary = np.mean(np.sort(max_elem_norm[max_elem_norm['label'] == 1]['proba_gap'])[:n_min])\n",
    "\n",
    "\n",
    "    relab = np.zeros(n_samples -1)\n",
    "    for i in range(n_samples -1):\n",
    "        if max_elem_norm.loc[max_elem_norm.index[i],'proba_gap'] < l_boundary:\n",
    "            relab[i] = -1\n",
    "        elif max_elem_norm.loc[max_elem_norm.index[i],'label'] == 1 or max_elem_norm.loc[max_elem_norm.index[i],'proba_gap'] >= 0:\n",
    "            relab[i] = 1\n",
    "        else:\n",
    "            relab[i] = 0\n",
    "    max_elem_norm['relab'] = relab\n",
    "\n",
    "    for i in range(n_samples -1):\n",
    "        if max_elem_norm.loc[max_elem_norm.index[i],'label'] == 1:\n",
    "            max_elem_norm.loc[max_elem_norm.index[i],'relab'] = 1\n",
    "    B=10000\n",
    "    labeled_data = max_elem_norm[max_elem_norm['relab'] != 0].copy()\n",
    "    output_labeled = labeled_data['relab'].to_numpy()\n",
    "    list_of_index = labeled_data.index\n",
    "    labeled_data = labeled_data.reset_index(drop=True)\n",
    "    labeled_data = labeled_data.to_numpy()[:,:-4]\n",
    "    unlabeled_data = max_elem_norm.drop(index=list_of_index,axis=0)\n",
    "    unlabeled_data = unlabeled_data.to_numpy()[:,:-4]\n",
    "    n_unlabeled = unlabeled_data.shape[0]\n",
    "    n_labels = labeled_data.shape[0]\n",
    "    capital_k = np.zeros((n_labels,n_labels))\n",
    "    kappa = np.zeros(n_labels)\n",
    "\n",
    "\n",
    "    #construction of capital_k\n",
    "    for i in range(n_labels):\n",
    "        for j in range(i,n_labels):\n",
    "            capital_k[i,j] = rbf(x=labeled_data[i,:],y=labeled_data[j,:])\n",
    "\n",
    "    capital_k = capital_k + capital_k.T\n",
    "    for i in range(n_labels):\n",
    "        capital_k[i,i] = 1\n",
    "\n",
    "    capital_k[np.where(np.isnan(capital_k) == True)] = 0\n",
    "\n",
    "    #construction of kappa\n",
    "    ratio_lab_unlab = n_labels/n_unlabeled\n",
    "\n",
    "    for i in range(n_labels):\n",
    "        vector = np.zeros(n_unlabeled)\n",
    "        for k in range(n_unlabeled):\n",
    "            vector[k] = rbf(x=labeled_data[i,:],y=unlabeled_data[k,:])    \n",
    "        kappa[i] = ratio_lab_unlab*np.sum(vector)\n",
    "\n",
    "    kappa = -kappa\n",
    "\n",
    "\n",
    "\n",
    "    ones_transposed = np.ones(n_labels).reshape(1,n_labels)\n",
    "    a_mat = np.vstack((ones_transposed,ones_transposed*-1,\n",
    "                   np.eye(n_labels),np.eye(n_labels)*-1))\n",
    "    epsilon = (np.sqrt(n_labels)-1)/np.sqrt(n_labels)\n",
    "    ub_mat = np.vstack((n_labels*(1+epsilon),n_labels*(epsilon-1),\n",
    "                        np.ones(n_labels).reshape(n_labels,1)*B,\n",
    "                        np.zeros(n_labels).reshape(n_labels,1)))\n",
    "\n",
    "\n",
    "\n",
    "    beta_opti = solve_qp(P=capital_k,q=kappa,G=a_mat,h=ub_mat,solver='cvxopt')\n",
    "\n",
    "\n",
    "    svm_weighted = SVC().fit(X=labeled_data,y=output_labeled,sample_weight=beta_opti)\n",
    "\n",
    "    predictions_weighted = svm_weighted.predict(max_elem_norm.to_numpy()[:,:-4])\n",
    "\n",
    "    positive = 0\n",
    "    true_positive = 0\n",
    "    for i in range(n_samples-1):\n",
    "        if predictions_weighted[i] == 1:\n",
    "            positive += 1\n",
    "            if max_elem_norm.loc[max_elem_norm.index[i],'class'] == 1:\n",
    "                true_positive += 1\n",
    "\n",
    "\n",
    "    recall_pgpu = true_positive/max_elem_norm[max_elem_norm['class'] == 1].shape[0]\n",
    "    weird_estim_pgpu = (recall_pgpu**2)/(positive/max_elem_norm.shape[0])\n",
    "    print('the element taken out of the sample is : ', particular_element, '\\n',\n",
    "        'the recall of pgpu on train set is :', recall_pgpu, '\\n', \n",
    "      'the weird metric of pgpu on train set is :', weird_estim_pgpu)\n",
    "    element_to_test = element_to_test.reshape(1,-1)\n",
    "    result_for_positive_instances[gen_count] = svm_weighted.predict(element_to_test)[0]\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad41639-5bed-405e-ae1f-9a03a806b978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
